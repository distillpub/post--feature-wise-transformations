<!doctype html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://distill.pub/template.v2.js"></script>
  <style>.subgrid {
  grid-column: screen; 
  display: grid; 
  grid-template-columns: inherit;
  grid-template-rows: inherit;
  grid-column-gap: inherit;
  grid-row-gap: inherit;
}

d-figure.base-grid {
  grid-column: screen;
  background: hsl(0, 0%, 97%);
  padding: 20px 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

d-figure {
  margin-bottom: 1em;
  position: relative;
}

d-figure > figure {
  margin-top: 0;
  margin-bottom: 0;
}

.shaded-figure {
  background-color: hsl(0, 0%, 97%);
  border-top: 1px solid hsla(0, 0%, 0%, 0.1);
  border-bottom: 1px solid hsla(0, 0%, 0%, 0.1);
  padding: 30px 0;
}

.pointer {
  position: absolute;
  width: 26px;
  height: 26px;
  top: 26px;
  left: -48px;
}

.figure-element, .figure-line, .figure-path {
  stroke: #666;
  stroke-miterlimit: 10px;
  stroke-width: 1.5px;
}

.figure-element {
  fill: #fff;
  fill-opacity: 0.8;
}

.figure-line {
  fill: none;
}

.figure-path {
  fill: #666;
  stroke-width: 1px;
}

.figure-group {
  fill: #f9f9f9;
  stroke: #666;
  stroke-width: 1.5px;
  stroke-opacity: 0.6;
  stroke-miterlimit: 10px;
}

.figure-faded {
  opacity: 0.35;
}

.figure-box {
  rx: 6px;
  ry: 6px;
}

.figure-dashed {
  stroke: #666;
  stroke-width: 1.5px;
  stroke-miterlimit: 10px;
  stroke-dasharray: 5, 5;
}

.figure-text {
  fill: #000;
  opacity: 0.6;
  font-size: 13px;
}

.figure-text-faded {
  opacity: 0.35;
}

.figure-large-text {
  font-size: 18px;
}

.subscript {
  font-size: 8px;
}

.figure-film-generator {
  stroke: #006064;
  fill: #80DEEA;
}

.figure-film-generator-shaded {
  stroke: #006064;
  fill: #00838F;
}

.figure-filmed-network {
  stroke: #BF360C;
  fill: #FFAB91;
}

.todo {
  color: red;
}


.tooltip {
  position: absolute;
  max-width: 300px;
  max-height: 300px;
  pointer-events: none;
  transition: opacity;
}

.collapsible {
  cursor: pointer;
  padding-top: 12px;
  padding-bottom: 12px;
  width: 100%;
  border: none;
  text-align: left;
  outline: none;
  font-size: 25px;
  font-weight: 700;
  background-color: white;
  color: rgba(0, 0, 0, 0.8);
  padding: 0.5em;
  margin: 0.2em;
  transform: translateX(0px);
  transition: 
      color 0.1s ease-out,
      transform 0.25s ease;
}

.collapsible:hover {
  border-bottom: 1px solid inset;
  color: rgba(0, 0, 0, 0.4);
  transform: translateX(10px);
  transition: 
      transform 0.25s ease;
}

d-article .content {
  display: none;
  overflow: hidden;
  background-color: none;
}

.expand-collapse-button {
  cursor: pointer;
  border: none;
  outline: none;
  font-size: 18px;
  font-weight: 700;
  float: right;
}

#clevr-plot-svg {
 width:440px;
 height:400px
}

#style-transfer-plot-svg {
 width:440px;
 height:400px
}
</style>
  <script src="https://d3js.org/d3.v4.min.js"></script>
  <script src="https://d3js.org/d3-selection-multi.v1.min.js"></script>
  <script src="https://ariutta.github.io/svg-pan-zoom/dist/svg-pan-zoom.js"></script>
</head>

<body>

<d-front-matter>
  <script type="text/json">{
    "title": "Feature-wise transformations",
    "description": "A simple and surprisingly effective family of conditioning mechanisms.",
    "authors": [
      {
        "author": "Vincent Dumoulin",
        "authorURL": "https://vdumoulin.github.io",
        "affiliations": [{"name": "Google Brain", "url": "https://ai.google/research/teams/brain"}]
      },
      {
        "author": "Ethan Perez",
        "authorURL": "http://ethanperez.net/",
        "affiliations": [
          {"name": "Rice University", "url": "http://www.rice.edu/"},
          {"name": "MILA", "url": "https://mila.quebec/en/"}
        ]
      },
      {
        "author": "Nathan Schucher",
        "authorURL": "https://nathanschucher.com/",
        "affiliations": [{"name": "Element AI", "url": "https://element.ai/"}]
      },
      {
        "author": "Florian Strub",
        "authorURL": "https://fstrub95.github.io/",
        "affiliations": [{"name": "Univ. of Lille, Inria", "url": "https://team.inria.fr/sequel/"}]
      },
      {
        "author": "Harm de Vries",
        "authorURL": "http://www-etud.iro.umontreal.ca/~devries/",
        "affiliations": [{"name": "MILA", "url": "https://mila.quebec/en/"}]
      },
      {
        "author": "Aaron Courville",
        "authorURL": "https://aaroncourville.wordpress.com/",
        "affiliations": [{"name": "MILA", "url": "https://mila.quebec/en/"}]
      },
      {
        "author": "Yoshua Bengio",
        "authorURL": "http://www.iro.umontreal.ca/~bengioy/yoshua_en/",
        "affiliations": [{"name": "MILA", "url": "https://mila.quebec/en/"}]
      }
    ],
    "katex": {
      "delimiters": [
        {
          "left": "$",
          "right": "$",
          "display": false
        },
        {
          "left": "$$",
          "right": "$$",
          "display": true
        }
      ]
    }
  }</script>
</d-front-matter>

<d-title>
  <h1>Feature-wise transformations</h1>
  <p>A simple and surprisingly effective family of conditioning mechanisms.</p>
  <div class="l-page" id="vtoc"></div>
</d-title>

<d-article>
  <p>
    Many real-world problems require integrating multiple sources of information.
    Sometimes these problems involve multiple, distinct modalities of
    information &mdash; vision, language, audio, etc. &mdash; as is required
    to understand a scene in a movie or answer a question about an image.
    Other times, these problems involve multiple sources of the same
    kind of input, i.e. when summarizing several documents or drawing one
    image in the style of another.
  </p>
  <figure class="l-body-outset">
    <svg viewBox="0 0 888 280" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><filter x="0" y="0" width="1" height="1" id="zoolander-text-background"><feFlood flood-color="#fdf6f2"></feFlood><feComposite in="SourceGraphic"></feComposite></filter></defs><g transform="translate(70, 0)"><text x="0" y="210" class="figure-text"><tspan> Video and audio must be understood in the context of each </tspan><tspan x="0" dy="1.5em"> other to understand the scene. </tspan><tspan x="0" dy="2em" style="font-style: italic;"> Credit: still frame from the movie Charade. </tspan></text><image x="0" y="0" width="364" height="182" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/charade.png"></image><path d="M 0 0 C 15 -50 27.5 -50 42.5 0 S 70 50 85 0 S 110.5 -50 127.5 0 S 155 50 170 0 S 197.5 -50 212.5 0 S 240 50 255 0 S 282.5 -50 297.5 0 S 325 50 340 0 S 367.5 -50 382.5 0 S 410 50 425 0" style="fill: none; stroke: #fdf6f2; stroke-width: 3px;" transform="scale(0.50) translate(10, 53)"></path><text filter="url(#zoolander-text-background)" x="110" y="25" dy="0.4em" style="opacity: 1; text-anchor: middle;" class="figure-text">&quot;Are you sure there&#x27;s no mistake?&quot;</text></g><g transform="translate(530, 0)"><text x="0" y="210" class="figure-text"><tspan> An image needs to be processed in the context of </tspan><tspan x="0" dy="1.5em"> a question being asked. </tspan><tspan x="0" dy="2em" style="font-style: italic;"> Credit: image-question pair from the CLEVR dataset. </tspan></text><image x="0" y="0" width="297.18" height="182" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/clevr_image.jpg"></image><text x="10" y="120" dy="0.4em" style="fill: white; opacity: 0.8; font-size: 10px;" class="figure-text"><tspan>Are there an equal</tspan><tspan x="10" dy="1.5em">number of large</tspan><tspan x="10" dy="1.5em">things and metal</tspan><tspan x="10" dy="1.5em">spheres?</tspan></text></g></svg>
  </figure>
  <p>
    When approaching such problems, it often makes sense to process one source
    of information <em>in the context of</em> another; for instance, in the
    right example above, one can extract meaning from the image in the context
    of the question. In machine learning, we often refer to this context-based
    processing as <em>conditioning</em>: the computation carried out by a model
    is conditioned or <em>modulated</em> by information extracted from an
    auxiliary input.
  </p>
  <p>
    Finding an effective way to condition on or fuse sources of information
    is an open research problem, and
    <!-- Introduction -->
    in this article, we concentrate on a specific family of approaches we call
    <em>feature-wise transformations</em>.
    <!-- Related Work -->
    We will examine the use of feature-wise transformations in many neural network
    architectures to solve a surprisingly large and diverse set of problems;
    <!-- Experiments -->
    their success, we will argue, is due to being flexible enough to learn an
    effective representation of the conditioning input in varied settings.
    In the language of multi-task learning, where the conditioning signal is
    taken to be a task description, feature-wise transformations
    learn a task representation which allows them to capture and leverage the
    relationship between multiple sources of information, even in remarkably
    different problem settings.
  </p>

  <hr/>

  <h2>Feature-wise transformations</h2>
  <p>
    To motivate feature-wise transformations, we start with a basic example,
    where the two inputs are images and category labels, respectively. For the
    purpose of this example, we are interested in building a generative model of
    images of various classes (puppy, boat, airplane, etc.). The model takes as
    input a class and a source of random noise (e.g., a vector sampled from a
    normal distribution) and outputs an image sample for the requested class.
  </p>
  <figure class="l-body">
    <svg viewBox="0 0 704 170" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><g transform="translate(520, 0)"><text x="0" y="10" dy="1em" class="figure-text"><tspan> A <tspan style="font-weight: bold;">decoder-based</tspan></tspan><tspan x="0" dy="1.5em"><tspan style="font-weight: bold;">generative model</tspan></tspan><tspan x="0" dy="1.5em"> maps a source of </tspan><tspan x="0" dy="1.5em"> noise to a sample <tspan x="0" dy="1.5em"> in the context of the </tspan><tspan x="0" dy="1.5em"> &quot;puppy&quot; class. </tspan></text></g><g transform="translate(30, 0)"><text x="0" y="85" dy="0.4em" class="figure-text">noise</text><path d="M 40 85 L 75 85" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(75, 85)" class="figure-path"></use><text x="155" y="10" style="text-anchor: middle;" class="figure-text">&quot;puppy&quot;</text><path d="M 155 20 L 155 40" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(155, 40)" class="figure-path"></use><g transform="translate(80, 45)"><rect width="150" height="80" class="figure-group figure-box"></rect><text x="75" y="40" dy="0.4em" style="text-anchor: middle;" class="figure-text">decoder</text></g><path d="M 230 85 L 300 85" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(300, 85)" class="figure-path"></use><image x="305" y="10" width="150" height="150" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/puppy.jpg"></image></g></svg>
  </figure>
  <p>
    Our first instinct might be to build a separate model for each
    class. For a small number of classes this approach is not too bad a solution,
    but for thousands of classes, we quickly run into scaling issues, as the number
    of parameters to store and train grows with the number of classes.
    We are also missing out on the opportunity to leverage commonalities between
    classes; for instance, different types of dogs (puppy, terrier, dalmatian,
    etc.) share visual traits and are likely to share computation when
    mapping from the abstract noise vector to the output image.
  </p>
  <p>
    Now let's imagine that, in addition to the various classes, we also need to
    model attributes like size or color. In this case, we can't
    reasonably expect to train a separate network for <em>each</em> possible
    conditioning combination! Let's examine a few simple options.
  </p>
  <p>
    A quick fix would be to concatenate a representation of the conditioning
    information to the noise vector and treat the result as the model's input.
    This solution is quite parameter-efficient, as we only need to increase
    the size of the first layer's weight matrix. However, this approach makes the implicit
    assumption that the input is where the model needs to use the conditioning information.
    Maybe this assumption is correct, or maybe it's not; perhaps the
    model does not need to incorporate the conditioning information until late
    into the generation process (e.g., right before generating the final pixel
    output when conditioning on texture). In this case, we would be forcing the model to
    carry this information around unaltered for many layers.
  </p>
  <p>
    Because this operation is cheap, we might as well avoid making any such
    assumptions and concatenate the conditioning representation to the input of
    <em>all</em> layers in the network. Let's call this approach
    <em>concatenation-based conditioning</em>.
  </p>
  <figure class="l-body">
    <svg viewBox="0 0 704 230" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path></defs><text x="260" y="10" dy="1em" class="figure-text"><tspan><tspan style="font-weight: bold;">Concatenation-based conditioning</tspan></tspan><tspan x="260" dy="1.5em"> simply concatenates the conditioning </tspan><tspan x="260" dy="1.5em"> representation to the input. </tspan></text><text x="445" y="100" dy="0.4em" class="figure-text"><tspan> The result is passed </tspan><tspan x="445" dy="1.5em"> through a linear layer </tspan><tspan x="445" dy="1.5em"> to produce the output. </tspan></text><g transform="translate(10, 70)"><text x="0" y="90" dy="0.4em" class="figure-text"> input </text><g transform="translate(40, 60)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use></g><text x="191" y="-30" dy="-0.35em" style="text-anchor: end;" class="figure-text"><tspan>conditioning</tspan><tspan x="191" dy="1.5em">representation</tspan></text><g transform="translate(201, -60)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-film-generator figure-element"></use></g><g transform="translate(191, 30)"><rect width="40" height="120" class="figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">concatenate</text></g><g transform="translate(302, 30)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 80)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 100)" class="figure-filmed-network figure-element"></use></g><g transform="translate(380, 30)"><rect width="40" height="120" class="figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">linear</text></g><g transform="translate(570, 50)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use></g><text x="600" y="90" dy="0.4em" class="figure-text"> output </text><path d="M 60 90 L 186 90" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(186, 90)" class="figure-path"></use><path d="M 231 90 L 297 90" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(297, 90)" class="figure-path"></use><path d="M 327 90 L 375 90" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(375, 90)" class="figure-path"></use><path d="M 420 90 L 565 90" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(565, 90)" class="figure-path"></use><path d="M 211 0 L 211 25" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(211, 25)" class="figure-path"></use></g></svg>
  </figure>
  <p>
    Another efficient way to integrate conditioning information into the network
    is via <em>conditional biasing</em>, namely, by adding a <em>bias</em> to
    the hidden layers based on the conditioning representation.
  </p>
  <figure class="l-body">
    <svg viewBox="0 0 704 300" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path></defs><text x="340" y="30" dy="1em" class="figure-text"><tspan><tspan style="font-weight: bold;">Conditional biasing</tspan> first maps </tspan><tspan x="340" dy="1.5em"> the <tspan style="font-weight: bold;">conditioning representation</tspan></tspan><tspan x="340" dy="1.5em"> to a bias vector. </tspan></text><text x="340" y="200" dy="1em" class="figure-text"><tspan> The bias vector is then </tspan><tspan x="340" dy="1.5em"> added to the input. </tspan></text><g transform="translate(-10, 10)"><text x="20" y="250" dy="-0.5em" style="text-anchor: begin;" class="figure-text">input</text><text x="605" y="250" dy="-0.5em" style="text-anchor: begin;" class="figure-text">output</text><g transform="translate(60, 200)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use></g><path d="M 80 240 L 300 240" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(300, 240)" class="figure-path"></use><g transform="translate(315, 240)"><circle r="10" class="figure-element"></circle><path d="M -5 0 L 5 0" class="figure-line"></path><path d="M 0 -5 L 0 5" class="figure-line"></path></g><path d="M 325 240 L 570 240" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(570, 240)" class="figure-path"></use><g transform="translate(575, 200)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use></g><text x="20" y="60" dy="-0.5em" style="font-weight: bold;" class="figure-text"><tspan>conditioning</tspan><tspan x="20" dy="1.5em">representation</tspan></text><g transform="translate(170, 0)"><rect width="40" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">linear</text></g><g transform="translate(305, 20)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-film-generator figure-element"></use></g><path d="M 120 60 L 165 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(165, 60)" class="figure-path"></use><path d="M 210 60 L 300 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(300, 60)" class="figure-path"></use><path d="M 315 100 L 315 225" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(315, 225)" class="figure-path"></use></g></svg>
  </figure>
  <p>
    Interestingly, conditional biasing can be thought of as another way to
    implement concatenation-based conditioning. Consider a fully-connected
    linear layer applied to the concatenation of an input
    <d-math>\mathbf{x}</d-math> and a conditioning representation
    <d-math>\mathbf{z}</d-math>:
    <d-footnote>
      The same argument applies to convolutional networks, provided we ignore
      the border effects due to zero-padding.
    </d-footnote>
  </p>
  <figure class="l-body">
    <svg viewBox="0 0 704 420" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-up" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="row-left" d="M 0 6 a 6 6 0 0 1 6 -6 l 14 0 l 0 20 l -14 0 a 6 6 0 0 1 -6 -6 Z"></path><path id="row-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="row-right" d="M 0 0 l 14 0 a 6 6 0 0 1 6 6 l 0 8 a 6 6 0 0 1 -6 6 l -14 0 Z"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path><path id="matrix-top-left" d="M 0 6 a 6 6 0 0 1 6 -6 l 14 0 l 0 20 l -20 0 Z"></path><path id="matrix-top-right" d="M 0 0 l 14 0 a 6 6 0 0 1 6 6 l 0 14l -20 0 Z"></path><path id="matrix-bottom-left" d="M 0 0 l 20 0 l 0 20 l -14 0 a 6 6 0 0 1 -6 -6 Z"></path><path id="matrix-bottom-right" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -14 0 Z"></path><path id="matrix-center" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="curly-brace-vertical" d="M 0 0 C 12 0 0 30 12 30 C 0 30 12 60 0 60"></path></defs><g transform="translate(10, 20)"><text x="0" y="0" class="figure-text"><tspan><tspan style="font-weight: bold;">Concatenation-based conditioning</tspan></tspan><tspan x="0" dy="1.5em"> is equivalent to <tspan style="font-weight: bold;">conditional biasing</tspan>. </tspan></text></g><g transform="translate(300, 20)"><text x="0" y="0" class="figure-text"><tspan> We can decompose the matrix- </tspan><tspan x="0" dy="1.5em"> vector product into two matrix- </tspan><tspan x="0" dy="1.5em"> vector subproducts. </tspan></text></g><g transform="translate(540, 20)"><text x="0" y="0" class="figure-text"><tspan> We can then add the </tspan><tspan x="0" dy="1.5em"> resulting two vectors. </tspan><tspan x="0" dy="1.5em"> The <tspan style="font-weight: bold;">z</tspan>-dependent vector </tspan><tspan x="0" dy="1.5em"> is a conditional bias. </tspan></text></g><g transform="translate(60, 90)"><g transform="translate(-50, 100)"><g><use xlink:href="#matrix-top-left" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-top-right" transform="translate(100, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(100, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(100, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-bottom-left" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 60)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 60)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-bottom-right" transform="translate(100, 60)" class="figure-film-generator figure-element"></use><text x="60" y="90" dy="0.4em" style="text-anchor: middle;" class="figure-text">W</text></g><g transform="translate(125, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 80)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 100)" class="figure-film-generator figure-element"></use><use xlink:href="#curly-brace-vertical" transform="translate(25, 0)" class="figure-line"></use><use xlink:href="#curly-brace-vertical" transform="translate(25, 60)" class="figure-line"></use><text x="45" y="30" dy="0.4em" style="font-weight: bold;" class="figure-text">x</text><text x="45" y="90" dy="0.4em" style="font-weight: bold;" class="figure-text">z</text></g></g><g transform="translate(240, 10)"><g><use xlink:href="#matrix-top-left" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-bottom-left" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 60)" class="figure-filmed-network figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 60)" class="figure-filmed-network figure-element"></use></g><g transform="translate(65, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#curly-brace-vertical" transform="translate(25, 0)" class="figure-line"></use><text x="45" y="30" dy="0.4em" style="font-weight: bold;" class="figure-text">x</text></g></g><g transform="translate(240, 240)"><g><use xlink:href="#matrix-center" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-top-right" transform="translate(40, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-bottom-right" transform="translate(40, 60)" class="figure-film-generator figure-element"></use></g><g transform="translate(65, 0)"><use xlink:href="#column-middle" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#curly-brace-vertical" transform="translate(25, 0)" class="figure-line"></use><text x="45" y="30" dy="0.4em" style="font-weight: bold;" class="figure-text">z</text></g></g><g transform="translate(405, 10)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use></g><g transform="translate(405, 240)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-film-generator figure-element"></use></g><g transform="translate(565, 150)"><circle cx="10" cy="10" r="10" class="figure-element"></circle><path d="M 10 5 l 0 10" class="figure-line"></path><path d="M 5 10 l 10 0" class="figure-line"></path></g><g transform="translate(615, 120)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use></g><path d="M 135 130 C 205 130 165 40 235 50" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(235, 50)" class="figure-path"></use><path d="M 135 190 C 205 190 165 290 235 280" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(235, 280)" class="figure-path"></use><path d="M 365 50 l 35 0" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(400, 50)" class="figure-path"></use><path d="M 365 280 l 35 0" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(400, 280)" class="figure-path"></use><path d="M 430 50 L 569 50 a 6 6 0 0 1 6 6 L 575 145" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(575, 145)" class="figure-path"></use><path d="M 430 280 L 569 280 a 6 6 0 0 0 6 -6 L 575 175" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(575, 175)" class="figure-path"></use><text x="435" y="295" class="figure-text">conditional bias</text><path d="M 585 160 l 20 0" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(610, 160)" class="figure-path"></use></g></svg>
  </figure>
  <p>
    Yet another efficient way to integrate class information into the network is
    via <em>conditional scaling</em>, i.e., scaling hidden layers
    based on the conditioning representation.
  </p>
  <figure class="l-body">
    <svg viewBox="0 0 704 300" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path></defs><text x="340" y="30" dy="1em" class="figure-text"><tspan><tspan style="font-weight: bold;">Conditional scaling</tspan> first maps the </tspan><tspan x="340" dy="1.5em"><tspan style="font-weight: bold;">conditioning representation</tspan> to a </tspan><tspan x="340" dy="1.5em"> scaling vector. </tspan></text><text x="340" y="200" dy="1em" class="figure-text"><tspan> The scaling vector is then multiplied </tspan><tspan x="340" dy="1.5em"> with the input. </tspan></text><g transform="translate(-10, 10)"><text x="20" y="250" dy="-0.5em" style="text-anchor: begin;" class="figure-text">input</text><text x="605" y="250" dy="-0.5em" style="text-anchor: begin;" class="figure-text">output</text><g transform="translate(60, 200)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use></g><path d="M 80 240 L 300 240" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(300, 240)" class="figure-path"></use><g transform="translate(315, 240)"><circle r="10" class="figure-element"></circle><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 325 240 L 570 240" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(570, 240)" class="figure-path"></use><g transform="translate(575, 200)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use></g><text x="20" y="60" dy="-0.5em" style="font-weight: bold;" class="figure-text"><tspan>conditioning</tspan><tspan x="20" dy="1.5em">representation</tspan></text><g transform="translate(170, 0)"><rect width="40" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">linear</text></g><g transform="translate(305, 20)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-film-generator figure-element"></use></g><path d="M 120 60 L 165 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(165, 60)" class="figure-path"></use><path d="M 210 60 L 300 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(300, 60)" class="figure-path"></use><path d="M 315 100 L 315 225" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(315, 225)" class="figure-path"></use></g></svg>
  </figure>
  <p>
    A special instance of conditional scaling is feature-wise sigmoidal gating:
    we scale each feature by a value between <d-math>0</d-math> and
    <d-math>1</d-math> (enforced by applying the logistic function), as a
    function of the conditioning representation. Intuitively, this gating allows
    the conditioning information to select which features are passed forward
    and which are zeroed out.
  </p>
  <p>
    Given that both additive and multiplicative interactions seem natural and
    intuitive, which approach should we pick? One argument in favor of
    <em>multiplicative</em> interactions is that they are useful in learning
    relationships between inputs, as these interactions naturally identify
    "matches": multiplying elements that agree in sign yields larger values than
    multiplying elements that disagree. This property is why dot products are
    often used to determine how similar two vectors are.
    <d-footnote>
      Multiplicative interactions alone have had a history of success in various
      domains &mdash; see <a href="#bibliographic-notes">Bibliographic Notes</a>.
    </d-footnote>
    One argument in favor of <em>additive</em> interactions is that they are
    more natural for applications that are less strongly dependent on the
    joint values of two inputs, like feature aggregation or feature detection
    (i.e., checking if a feature is present in either of two inputs).
  </p>
  <p>
    In the spirit of making as few assumptions about the problem as possible,
    we may as well combine <em>both</em> into a
    conditional <em>affine transformation</em>.
    <d-footnote>
      An affine transformation is a transformation of the form
      <d-math>y = m * x + b</d-math>.
    </d-footnote>
  </p>
  <p>
    All methods outlined above share the common trait that they act at the
    <em>feature</em> level; in other words, they leverage <em>feature-wise</em>
    interactions between the conditioning representation and the conditioned
    network. It is certainly possible to use more complex interactions,
    but feature-wise interactions often strike a happy compromise between
    effectiveness and efficiency: the number of scaling and/or shifting
    coefficients to predict scales linearly with the number of features in the
    network. Also, in practice, feature-wise transformations (often compounded
    across multiple layers) frequently have enough capacity to model complex
    phenomenon in various settings.
  </p>
  <p>
    Lastly, these transformations only enforce a limited inductive bias and
    remain domain-agnostic. This quality can be a downside, as some problems may
    be easier to solve with a stronger inductive bias.  However, it is this
    characteristic which also enables these transformations to be so widely
    effective across problem domains, as we will later review.
  </p>
  <h3>Nomenclature</h3>
  <p>
    To continue the discussion on feature-wise transformations we need to
    abstract away the distinction between multiplicative and additive
    interactions. Without losing generality, let's focus on feature-wise affine
    transformations, and let's adopt the nomenclature of Perez et al.
    <d-cite key="perez2018film"></d-cite>, which formalizes conditional affine
    transformations under the acronym <em>FiLM</em>, for Feature-wise Linear
    Modulation.
    <d-footnote>
      Strictly speaking, <em>linear</em> is a misnomer, as we allow biasing, but
      we hope the more rigorous-minded reader will forgive us for the sake of a
      better-sounding acronym.
    </d-footnote>
  </p>
  <p>
    We say that a neural network is modulated using FiLM, or <em>FiLM-ed</em>,
    after inserting <em>FiLM layers</em> into its architecture. These layers are
    parametrized by some form of conditioning information, and the mapping from
    conditioning information to FiLM parameters (i.e., the shifting and scaling
    coefficients) is called the <em>FiLM generator</em>.
    In other words, the FiLM generator predicts the parameters of the FiLM
    layers based on some auxiliary input.
    Note that the FiLM parameters are parameters in one network but predictions
    from another network, so they aren't learnable parameters with fixed
    weights as in the fully traditional sense.
    For simplicity, you can assume that the FiLM generator outputs the
    concatenation of all FiLM parameters for the network architecture.
  </p>
  <figure class="l-body">
    <svg viewBox="0 0 704 510" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><text x="0" y="20" class="figure-text"><tspan> The <tspan style="font-weight: bold;">FiLM generator</tspan> processes the conditioning information </tspan><tspan x="0" dy="1.5em"> and produces parameters that describe how the target network </tspan><tspan x="0" dy="1.5em"> should alter its computation. </tspan></text><path d="M420,10l0,510" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="460" y="20" class="figure-text"><tspan> Here, the <tspan style="font-weight: bold;">FiLM-ed network</tspan>&#x27;s computation </tspan><tspan x="460" dy="1.5em"> is conditioned by two FiLM layers. </tspan></text><g transform="translate(0, 40)"><g transform="translate(460, 40)"><text x="150" y="425" class="figure-text">output</text><path d="M130,399L130,430" class="figure-line"></path><use x="130" y="430" xlink:href="#arrow-down" class="figure-path"></use><g transform="translate(20, 337)" class="figure-faded"><rect width="222" height="62" class="figure-filmed-network figure-group figure-box"></rect><text x="111" y="31" dy="0.4em" style="text-anchor: middle;" class="figure-text">sub-network</text></g><path d="M130,305.5L130,332" class="figure-line"></path><use x="130" y="332" xlink:href="#arrow-down" class="figure-path"></use><g transform="translate(20, 275.5)" class="film-layer"><rect width="222" height="30" class="figure-filmed-network figure-group figure-box"></rect><text x="111" y="15" dy="0.4em" style="text-anchor: middle; font-weight: bold;" class="figure-text">FiLM</text></g><path d="M130,244L130,270.5" class="figure-line"></path><use x="130" y="270.5" xlink:href="#arrow-down" class="figure-path"></use><g transform="translate(20, 182)" class="figure-faded"><rect width="222" height="62" class="figure-filmed-network figure-group figure-box"></rect><text x="111" y="31" dy="0.4em" style="text-anchor: middle;" class="figure-text">sub-network</text></g><path d="M130,149.5L130,177" class="figure-line"></path><use x="130" y="177" xlink:href="#arrow-down" class="figure-path"></use><g transform="translate(20, 119.5)" class="film-layer"><rect width="222" height="30" class="figure-filmed-network figure-group figure-box"></rect><text x="111" y="15" dy="0.4em" style="text-anchor: middle; font-weight: bold;" class="figure-text">FiLM</text></g><path d="M130,88L130,114.5" class="figure-line"></path><use x="130" y="114.5" xlink:href="#arrow-down" class="figure-path"></use><g transform="translate(20, 26)" class="figure-faded"><rect width="222" height="62" class="figure-filmed-network figure-group figure-box"></rect><text x="111" y="31" dy="0.4em" style="text-anchor: middle;" class="figure-text">sub-network</text></g><text x="150" y="0" class="figure-text">input</text><path d="M130,-15l0,36" class="figure-line"></path><use x="130" y="21" xlink:href="#arrow-down" class="figure-path"></use></g><g transform="translate(0, 190)"><path d="M0,0l110,0" class="figure-line"></path><use x="110" y="0" xlink:href="#arrow-right" class="figure-path"></use><text x="0" y="0" dy="-0.8em" class="figure-text">conditioning</text></g><g transform="translate(115, 140)" class="film-generator"><rect width="180" height="100" class="figure-film-generator figure-group figure-box"></rect><text x="90" y="50" dy="0.4em" style="text-anchor: middle; font-weight: bold;" class="figure-text">FiLM generator</text></g><g><path d="M295,175l175,0" class="figure-line"></path><use x="475" y="175" xlink:href="#arrow-right" class="figure-path"></use><text x="305" y="175" dy="-0.8em" class="figure-text">FiLM parameters</text></g><g><path d="M295,205C360,205,387.5,205,387.5,265S415,330,475,330" class="figure-line"></path><use x="475" y="330" xlink:href="#arrow-right" class="figure-path"></use></g></g></svg>
  </figure>
  <p>
    As the name implies, a FiLM layer applies a feature-wise affine
    transformation to its input. By <em>feature-wise</em>, we mean that scaling
    and shifting are applied element-wise, or in the case of convolutional
    networks, feature map -wise.
    <d-footnote>
      To expand a little more on the convolutional case, feature maps can be
      thought of as the same feature detector being evaluated at different
      spatial locations, in which case it makes sense to apply the same affine
      transformation to all spatial locations.
    </d-footnote>
    In other words, assuming <d-math>\mathbf{x}</d-math> is a FiLM layer's
    input, <d-math>\mathbf{z}</d-math> is a conditioning input, and
    <d-math>\gamma</d-math> and <d-math>\beta</d-math> are
    <d-math>\mathbf{z}</d-math>-dependent scaling and shifting vectors,

    <d-math block>
        \textrm{FiLM}(\mathbf{x}) = \gamma(\mathbf{z}) \odot \mathbf{x}
                                                       + \beta(\mathbf{z}).
    </d-math>

    You can interact with the following fully-connected and convolutional FiLM
    layers to get an intuition of the sort of modulation they allow:
  </p>
  <figure class="l-body-outset" id="film-layer-diagram">
    <svg viewBox="0 0 888 650" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="big-row-left" d="M 0 6 a 6 6 0 0 1 6 -6 l 34 0 l 0 40 l -34 0 a 6 6 0 0 1 -6 -6 Z"></path><path id="big-row-middle" d="M 0 0 l 40 0 l 0 40 l -40 0 Z"></path><path id="big-row-right" d="M 0 0 l 34 0 a 6 6 0 0 1 6 6 l 0 28 a 6 6 0 0 1 -6 6 l -34 0 Z"></path><rect id="vector-patch-positive" width="30" height="30" rx="6" ry="6" opacity="0.8" style="fill: #FFAB91;"></rect><rect id="vector-patch-negative" width="30" height="30" rx="6" ry="6" opacity="0.8" style="fill: #80DEEA;"></rect><rect id="convolutional-patch-positive" width="20" height="20" rx="6" ry="6" opacity="0.8" style="fill: #FFAB91;"></rect><rect id="convolutional-patch-negative" width="20" height="20" rx="6" ry="6" opacity="0.8" style="fill: #80DEEA;"></rect><path id="convolutional-feature" d="M 0 0 l 30 0 l 0 30 l -30 0 Z"></path><g id="vector-arrow"><path d="M 0 0 l 0 -16"></path><path d="M 0 -16 l -4 4 l 4 -4 l 4 4"></path></g><g id="convolutional-arrow"><path d="M 0 0 L 0 -12"></path><path d="M -3 -9 L 0 -12 L 3 -9"></path></g></defs><g transform="translate(60, 0)"><g transform="translate(10, 10)" id="mlp-figure"><text x="240" y="10" class="figure-text"><tspan> In a <tspan style="font-weight: bold;">fully-connected</tspan> network, </tspan><tspan x="240" dy="1.5em"> FiLM applies a different affine </tspan><tspan x="240" dy="1.5em"> transformation to each feature. </tspan></text><text x="0" y="175" class="figure-text"><tspan> First, each feature (or channel) </tspan><tspan x="0" dy="1.5em"> is scaled by the corresponding </tspan><tspan x="0" dy="1.5em"><tspan style="font-family: serif; font-weight: bold;"></tspan> parameter. </tspan></text><text x="0" y="365" class="figure-text"><tspan> Then, each feature (or channel) </tspan><tspan x="0" dy="1.5em"> is shifted by the corresponding </tspan><tspan x="0" dy="1.5em"><tspan style="font-family: serif; font-weight: bold;"></tspan> parameter. </tspan></text><image x="130" y="220" height="27" width="27" xlink:href="images/pointer.svg"></image><image x="130" y="410" height="27" width="27" xlink:href="images/pointer.svg"></image><rect x="240" y="205" width="180" height="300" class="figure-group figure-box"></rect><g transform="translate(270, 125)" id="input-layer"><g transform="translate(0, 0)" class="feature"><use xlink:href="#big-row-left" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g><g transform="translate(40, 0)" class="feature"><use xlink:href="#big-row-middle" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g><g transform="translate(80, 0)" class="feature"><use xlink:href="#big-row-right" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g></g><line x1="330" y1="165" x2="330" y2="235" class="figure-line"></line><use xlink:href="#arrow-down" transform="translate(330, 235)" class="figure-path"></use><g transform="translate(0, 240)" id="gamma"><g transform="translate(0, 0)" class="feature"><use xlink:href="#big-row-left" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g><g transform="translate(40, 0)" class="feature"><use xlink:href="#big-row-middle" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g><g transform="translate(80, 0)" class="feature"><use xlink:href="#big-row-right" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g></g><text x="180" y="260" dy="1.5em" class="figure-text" style="font-family: serif; font-size: 20px;"></text><line x1="120" y1="260" x2="305" y2="260" class="figure-line"></line><use xlink:href="#arrow-right" transform="translate(305, 260)" class="figure-path"></use><g transform="translate(330, 260)"><ellipse cx="0" cy="0" rx="20" ry="20" style="fill: #e8e8e8;" class="figure-element"></ellipse><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><line x1="330" y1="280" x2="330" y2="330" class="figure-line"></line><use xlink:href="#arrow-down" transform="translate(330, 330)" class="figure-path"></use><g transform="translate(270, 335)" id="scaled-layer"><g transform="translate(0, 0)" class="feature"><use xlink:href="#big-row-left" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g><g transform="translate(40, 0)" class="feature"><use xlink:href="#big-row-middle" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g><g transform="translate(80, 0)" class="feature"><use xlink:href="#big-row-right" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g></g><line x1="330" y1="375" x2="330" y2="425" class="figure-line"></line><use xlink:href="#arrow-down" transform="translate(330, 425)" class="figure-path"></use><g transform="translate(0, 430)" id="beta"><g transform="translate(0, 0)" class="feature"><use xlink:href="#big-row-left" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g><g transform="translate(40, 0)" class="feature"><use xlink:href="#big-row-middle" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g><g transform="translate(80, 0)" class="feature"><use xlink:href="#big-row-right" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g></g><text x="180" y="450" dy="1.5em" class="figure-text" style="font-family: serif; font-size: 20px;"></text><line x1="120" y1="450" x2="305" y2="450" class="figure-line"></line><use xlink:href="#arrow-right" transform="translate(305, 450)" class="figure-path"></use><g transform="translate(330, 450)"><ellipse cx="0" cy="0" rx="20" ry="20" style="fill: #e8e8e8;" class="figure-element"></ellipse><line x1="0" y1="7.5" x2="0" y2="-7.5" class="figure-line"></line><line x1="-7.5" y1="0" x2="7.5" y2="0" class="figure-line"></line></g><line x1="330" y1="470" x2="330" y2="545" class="figure-line"></line><use xlink:href="#arrow-down" transform="translate(330, 545)" class="figure-path"></use><g transform="translate(270, 550)" id="shifted-layer"><g transform="translate(0, 0)" class="feature"><use xlink:href="#big-row-left" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g><g transform="translate(40, 0)" class="feature"><use xlink:href="#big-row-middle" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g><g transform="translate(80, 0)" class="feature"><use xlink:href="#big-row-right" class="figure-element"></use><use xlink:href="#vector-patch-negative" transform="translate(5, 5)" opacity="1" class="vector-patch"></use><use xlink:href="#vector-arrow" transform="translate(20, 20)" class="figure-line"></use></g></g></g><g transform="translate(422, 10)" id="cnn-figure"><text x="182" y="10" class="figure-text"><tspan> In a <tspan style="font-weight: bold;">convolutional</tspan> network, </tspan><tspan x="182" dy="1.5em"> FiLM applies a different affine </tspan><tspan x="182" dy="1.5em"> transformation to each channel, </tspan><tspan x="182" dy="1.5em"> consistent across spatial locations. </tspan></text><rect x="182" y="205" width="180" height="300" class="figure-group figure-box"></rect><g transform="translate(249.5, 120)" id="input-layer"><g><g transform="matrix(1, 0, -0.5, 0.5, 0, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 60, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 45, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 0, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g></g><g transform="translate(0, -20)"><g transform="matrix(1, 0, -0.5, 0.5, 0, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 60, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 45, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 0, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g></g><g transform="translate(0, -40)"><g transform="matrix(1, 0, -0.5, 0.5, 0, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 60, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 45, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 0, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g></g></g><line x1="272" y1="170" x2="272" y2="235" class="figure-line"></line><use xlink:href="#arrow-down" transform="translate(272, 235)" class="figure-path"></use><text x="120" y="260" dy="1.5em" class="figure-text" style="font-family: serif; font-size: 20px;"></text><path d="M90,240Q100,260,247,260" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(247, 260)" class="figure-path"></use><g transform="translate(272, 260)"><ellipse cx="0" cy="0" rx="20" ry="20" style="fill: #e8e8e8;" class="figure-element"></ellipse><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><line x1="272" y1="280" x2="272" y2="312.5" class="figure-line"></line><use xlink:href="#arrow-down" transform="translate(272, 312.5)" class="figure-path"></use><g transform="translate(249.5, 357.5)" id="scaled-layer"><g><g transform="matrix(1, 0, -0.5, 0.5, 0, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 60, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 45, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 0, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g></g><g transform="translate(0, -20)"><g transform="matrix(1, 0, -0.5, 0.5, 0, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 60, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 45, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 0, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g></g><g transform="translate(0, -40)"><g transform="matrix(1, 0, -0.5, 0.5, 0, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 60, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 45, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 0, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g></g></g><text x="120" y="450" dy="1.5em" class="figure-text" style="font-family: serif; font-size: 20px;"></text><path d="M90,430Q100,450,247,450" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(247, 450)" class="figure-path"></use><line x1="272" y1="407.5" x2="272" y2="425" class="figure-line"></line><use xlink:href="#arrow-down" transform="translate(272, 425)" class="figure-path"></use><g transform="translate(272, 450)"><ellipse cx="0" cy="0" rx="20" ry="20" style="fill: #e8e8e8;" class="figure-element"></ellipse><line x1="0" y1="7.5" x2="0" y2="-7.5" class="figure-line"></line><line x1="-7.5" y1="0" x2="7.5" y2="0" class="figure-line"></line></g><line x1="272" y1="470" x2="272" y2="545" class="figure-line"></line><use xlink:href="#arrow-down" transform="translate(272, 545)" class="figure-path"></use><g transform="translate(249.5, 590)" id="shifted-layer"><g><g transform="matrix(1, 0, -0.5, 0.5, 0, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 60, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 45, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 0, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g></g><g transform="translate(0, -20)"><g transform="matrix(1, 0, -0.5, 0.5, 0, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 60, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 45, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 0, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g></g><g transform="translate(0, -40)"><g transform="matrix(1, 0, -0.5, 0.5, 0, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 60, 0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 15, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 45, 15)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, -30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 0, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g><g transform="matrix(1, 0, -0.5, 0.5, 30, 30)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5, 5)" opacity="1" class="convolutional-patch"></use><use xlink:href="#convolutional-arrow" transform="translate(15, 15)" class="figure-line"></use></g></g></g></g></g></svg>
  </figure>
  <p>
    In addition to being a good abstraction of conditional feature-wise
    transformations, the FiLM nomenclature lends itself well to the notion of a
    <em>task representation</em>. From the perspective of multi-task learning,
    we can view the conditioning signal as the task description. More
    specifically, we can view the concatenation of all FiLM scaling and shifting
    coefcients as both an instruction on <em>how to modulate</em> the
    conditioned network and a <em>representation</em> of the task at hand. We
    will explore and illustrate this idea later on.
  </p>

  <hr/>

  <h2>Feature-wise transformations in the literature</h2>
  <p>
    Feature-wise transformations find their way into methods applied to many
    problem settings, but because of their simplicity, their effectiveness is
    seldom highlighted in lieu of other novel research contributions.  Below are
    a few notable examples of feature-wise transformations in the literature,
    grouped by application domain. The diversity of these applications
    underscores the flexible, general-purpose ability of feature-wise
    interactions to learn effective task representations.
  </p>
  <div style="width: 100%">
    <button class="expand-collapse-button" content-type="literature">expand all</button>
  </div>
  <button class="collapsible" content-name="vqa" content-type="literature">Visual question-answering<span style="float: right;">+</span></button>
  <p class="content" content-name="vqa" content-type="literature">
    Perez et al. <d-cite key="perez2017learning,perez2018film"></d-cite> use
    FiLM layers to build a visual reasoning model
    trained on the CLEVR dataset <d-cite key="johnson2017clevr"></d-cite> to
    answer multi-step, compositional questions about synthetic images.
  </p>
  <figure class="content l-body-outset" content-name="vqa" content-type="literature">
    <svg viewBox="0 0 888 500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-left" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><g transform="translate(10, 10)" class="film-generator"><text x="0" y="30" dy="1em" class="figure-text"><tspan> The <tspan style="font-weight: bold;">linguistic pipeline</tspan></tspan><tspan x="0" dy="1.5em"> acts as the FiLM generator. </tspan></text><text x="0" y="300" dy="1em" class="figure-text"><tspan> FiLM layers in each residual </tspan><tspan x="0" dy="1.5em"> block modulate the <tspan style="font-weight: bold;">visual</tspan></tspan><tspan x="0" dy="1.5em"><tspan style="font-weight: bold;">pipeline</tspan>. </tspan></text><g transform="translate(140, 0)"><image x="48" y="300" width="96" height="96" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/clevr_input.jpg"></image><g class="figure-faded"><path d="M 144 348 L 175 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(175, 348)" class="figure-path"></use></g><g transform="translate(180, 288)" class="figure-faded"><rect width="50" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="25" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 25, 60)" class="figure-text">feature extractor</text></g><g class="figure-faded"><path d="M 230 348 L 420 348" class="figure-line"></path><path d="M 230 348 C 260 348 242.5 278 272.5 278" class="figure-line"></path><path d="M 362.5 278 C 392.5 278 380 348 420 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(420, 348)" class="figure-path"></use></g><g transform="translate(272.5, 218)"><g transform="translate(0, 0)" class="figure-faded"><rect width="50" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="25" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 25, 60)" class="figure-text">sub-network</text></g><g class="figure-faded"><path d="M 50 60 L 60 60" class="figure-line"></path></g><g transform="translate(60, 0)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="font-weight: bold; text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">FiLM layer</text></g></g><g transform="translate(425, 288)" class="figure-faded"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">ReLU</text></g><path d="M 242.5 410 L 242.5 420 L 465 420 L 465 410" style="stroke-width: 1px;" class="figure-line"></path><text x="242.5" y="420" dy="1.5em" class="figure-text"><tspan> Each <tspan style="font-weight: bold;">residual block</tspan> has a </tspan><tspan x="242.5" dy="1.5em"> FiLM layer added to it. </tspan></text><g class="figure-faded"><path d="M 455 348 L 645 348" class="figure-line"></path><path d="M 455 348 C 485 348 467.5 278 497.5 278" class="figure-line"></path><path d="M 587.5 278 C 617.5 278 605 348 645 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(645, 348)" class="figure-path"></use></g><g transform="translate(497.5, 218)"><g transform="translate(0, 0)" class="figure-faded"><rect width="50" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="25" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 25, 60)" class="figure-text">sub-network</text></g><g class="figure-faded"><path d="M 50 60 L 60 60" class="figure-line"></path></g><g transform="translate(60, 0)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="font-weight: bold; text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">FiLM layer</text></g></g><g transform="translate(650, 288)" class="figure-faded"><rect width="50" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="25" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 25, 60)" class="figure-text">...</text></g><g class="figure-faded"><path d="M 700 348 L 730 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(730, 348)" class="figure-path"></use></g><g transform="translate(180, 100)"><rect width="520" height="40" class="figure-film-generator figure-element figure-box"></rect><text x="260" y="20" dy="0.4em" style="font-weight: bold; text-anchor: middle;" class="figure-text">linear</text></g><text x="180" y="150" dy="1em" class="figure-text">FiLM parameters</text><g class="figure-faded"><path d="M 700 60 L 724 60 a 6 6 0 0 1 6 6 L 730 114 a 6 6 0 0 1 -6 6 L 705 120" class="figure-line"></path><use xlink:href="#arrow-left" transform="translate(705, 120)" class="figure-path"></use><path d="M 675 140 L 675 283" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(675, 283)" class="figure-path"></use></g><path d="M 347.5 140 L 347.5 213" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(347.5, 213)" class="figure-path"></use><path d="M 572.5 140 L 572.5 213" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(572.5, 213)" class="figure-path"></use><g transform="translate(180, 30)"><g transform="translate(0, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">Are</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 30 30 L 76.66 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(76.66, 30)" class="figure-path"></use></g><g transform="translate(81.66, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">there</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 111.66 30 L 158.34 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(158.34, 30)" class="figure-path"></use></g><g transform="translate(163.34, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">more</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 193.34 30 L 240 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(240, 30)" class="figure-path"></use></g><g transform="translate(245, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">cubes</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 275 30 L 321.66 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(321.66, 30)" class="figure-path"></use></g><g transform="translate(326.66, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">than</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 356.66 30 L 403.34 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(403.34, 30)" class="figure-path"></use></g><g transform="translate(408.34, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">yellow</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 438.34 30 L 485 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(485, 30)" class="figure-path"></use></g><g transform="translate(490, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">things</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g></g></g></g></svg>
  </figure>
  <p class="content" content-name="vqa" content-type="literature">
    The model's linguistic pipeline is a FiLM generator which
    extracts a question representation that is linearly mapped to
    FiLM parameter values. Using these values, FiLM layers inserted within each
    residual block condition the visual pipeline. The model is trained
    end-to-end on image-question-answer triples. Strub et al.
    <d-cite key="strub2018visual"></d-cite> later on improved on the model by
    using an attention mechanism to alternate between attending to the language
    input and generating FiLM parameters layer by layer. This approach was
    better able to scale to settings with longer input sequences such as
    dialogue and was evaluated on the GuessWhat?! <d-cite key="vries2017guesswhat"></d-cite>
    and ReferIt <d-cite key="kazemzadeh2014referitgame"></d-cite> datasets.
  </p>
  <p class="content" content-name="vqa" content-type="literature">
    de Vries et al. <d-cite key="vries2017modulating"></d-cite> leverage FiLM
    to condition a pre-trained network. Their model's linguistic pipeline
    modulates the visual pipeline via conditional batch normalization,
    which can be viewed as a special case of FiLM. The model learns to answer natural language questions about
    real-world images on the GuessWhat?! <d-cite key="vries2017guesswhat"></d-cite>
    and VQAv1 <d-cite key="agrawal2015vqa"></d-cite> datasets.
  </p>
  <figure class="content l-body-outset" content-name="vqa" content-type="literature">
    <svg viewBox="0 0 888 470" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-left" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><g transform="translate(10, 10)"><text x="0" y="30" dy="1em" class="figure-text"><tspan> The <tspan style="font-weight: bold;">linguistic pipeline</tspan> acts </tspan><tspan x="0" dy="1.5em"> as the FiLM generator and also </tspan><tspan x="0" dy="1.5em"> directly passes the question </tspan><tspan x="0" dy="1.5em"> representation to the rest </tspan><tspan x="0" dy="1.5em"> of the network. </tspan></text><text x="0" y="300" dy="1em" class="figure-text"><tspan> FiLM layers modulate the pre- </tspan><tspan x="0" dy="1.5em"> trained <tspan style="font-weight: bold;">visual pipeline</tspan> by </tspan><tspan x="0" dy="1.5em"> making the batch normalization </tspan><tspan x="0" dy="1.5em"> parameters query-dependent. </tspan></text><g transform="translate(200, 0)"><image x="0" y="316" width="64" height="64" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/guesswhat_input.jpg"></image><path d="M 64 348 L 95 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(95, 348)" class="figure-path"></use><g transform="translate(100, 288)" class="figure-faded"><rect width="60" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 30, 60)" class="figure-text">sub-network</text></g><path d="M 160 348 L 175 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(175, 348)" class="figure-path"></use><g transform="translate(180, 288)" class="figure-faded"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">normalization</text></g><path d="M 210 348 L 225 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(225, 348)" class="figure-path"></use><g transform="translate(230, 288)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="font-weight: bold; text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">FiLM layer</text></g><path d="M 260 348 L 275 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(275, 348)" class="figure-path"></use><g transform="translate(280, 288)" class="figure-faded"><rect width="60" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 30, 60)" class="figure-text">sub-network</text></g><path d="M 340 348 L 355 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(355, 348)" class="figure-path"></use><g transform="translate(360, 288)" class="figure-faded"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">normalization</text></g><path d="M 390 348 L 405 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(405, 348)" class="figure-path"></use><g transform="translate(410, 288)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="font-weight: bold; text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">FiLM layer</text></g><path d="M 440 348 L 455 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(455, 348)" class="figure-path"></use><g transform="translate(460, 288)" class="figure-faded"><rect width="60" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 30, 60)" class="figure-text">...</text></g><path d="M 175 410 L 175 420 L 265 420 L 265 410" style="stroke-width: 1px;" class="figure-line"></path><text x="175" y="420" dy="1.5em" class="figure-text"><tspan> conditional batch </tspan><tspan x="175" dy="1.5em"> normalization </tspan></text><path d="M 355 410 L 355 420 L 445 420 L 445 410" style="stroke-width: 1px;" class="figure-line"></path><text x="355" y="420" dy="1.5em" class="figure-text"><tspan> conditional batch </tspan><tspan x="355" dy="1.5em"> normalization </tspan></text><path d="M 520 348 L 575 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(575, 348)" class="figure-path"></use><g transform="translate(100, 100)"><rect width="420" height="40" class="figure-film-generator figure-element figure-box"></rect><text x="210" y="20" dy="0.4em" style="font-weight: bold; text-anchor: middle;" class="figure-text">MLP</text></g><text x="100" y="150" dy="1em" class="figure-text">FiLM parameters</text><path d="M 520 60 L 544 60 a 6 6 0 0 1 6 6 L 550 114 a 6 6 0 0 1 -6 6 L 525 120" class="figure-line"></path><use xlink:href="#arrow-left" transform="translate(525, 120)" class="figure-path"></use><path d="M 550 110 L 550 154 a 6 6 0 0 0 6 6 L 575 160" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(575, 160)" class="figure-path"></use><path d="M 245 140 L 245 283" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(245, 283)" class="figure-path"></use><path d="M 425 140 L 425 283" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(425, 283)" class="figure-path"></use><path d="M 490 140 L 490 283" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(490, 283)" class="figure-path"></use><g transform="translate(580, 100)" style="opacity: 0.6;"><rect width="40" height="308" style="fill: #e0e0e0;" class="figure-element figure-box"></rect><text x="20" y="154" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 154)" class="figure-text">...</text></g><path d="M 620 254 L 650 254" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(650, 254)" class="figure-path"></use><g transform="translate(100, 30)"><g transform="translate(0, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">Is</text><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">LSTM</text></g></g><path d="M 30 30 L 92.5 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(92.5, 30)" class="figure-path"></use><g transform="translate(97.5, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">the</text><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">LSTM</text></g></g><path d="M 127.5 30 L 190 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(190, 30)" class="figure-path"></use><g transform="translate(195, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">umbrella</text><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">LSTM</text></g></g><path d="M 225 30 L 287.5 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(287.5, 30)" class="figure-path"></use><g transform="translate(292.5, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">upside</text><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">LSTM</text></g></g><path d="M 322.5 30 L 385 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(385, 30)" class="figure-path"></use><g transform="translate(390, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">down</text><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">LSTM</text></g></g></g></g></g></svg>
  </figure>
  <p class="content" content-name="vqa" content-type="literature">
    The visual pipeline consists of a pre-trained residual network that is
    fixed throughout training. The linguistic pipeline manipulates the visual
    pipeline by perturbing the residual network's batch normalization
    parameters, which re-scale and re-shift feature maps after activations
    have been normalized to have zero mean and unit variance.  As hinted
    earlier, conditional batch normalization can be viewed as an instance of
    FiLM where the post-normalization feature-wise affine transformation is
    replaced with a FiLM layer.
  </p>
  <button class="collapsible" content-name="style-transfer" content-type="literature">Style transfer<span style="float: right;">+</span></button>
  <p class="content" content-name="style-transfer" content-type="literature">
    Dumoulin et al. <d-cite key="dumoulin2017learned"></d-cite> use
    feature-wise affine transformations &mdash; in the form of conditional
    instance normalization layers &mdash; to condition a style transfer
    network on a chosen style image. Like conditional batch normalization
    discussed in the previous subsection,
    conditional instance normalization can be seen as an instance of FiLM
    where a FiLM layer replaces the post-normalization feature-wise affine
    transformation. For style transfer, the network models each style as a separate set of
    instance normalization parameters, and it applies normalization with these
    style-specific parameters.
  </p>
  <figure class="content l-body-outset" content-name="style-transfer" id="alrfas-diagram" content-type="literature">
    <svg viewBox="0 0 888 420" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><g transform="translate(10, 10)"><text x="0" y="0" dy="1em" class="figure-text"><tspan> The <tspan style="font-weight: bold;">FiLM generator</tspan></tspan><tspan x="0" dy="1.5em"> predicts parameters </tspan><tspan x="0" dy="1.5em"> describing the target style. </tspan></text><text x="0" y="250" dy="1em" class="figure-text"><tspan> The <tspan style="font-weight: bold;">style transfer network</tspan></tspan><tspan x="0" dy="1.5em"> is conditioned by making </tspan><tspan x="0" dy="1.5em"> the instance normalization </tspan><tspan x="0" dy="1.5em"> parameters style-dependent. </tspan></text><g transform="translate(-15, 0)"><image x="200" y="0" width="96" height="96" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/cassis_cap_lombard_opus_196.jpg"></image><g transform="translate(340, 0)"><rect width="420" height="96" class="figure-film-generator figure-element figure-box"></rect><text x="210" y="48" dy="0.4em" style="font-weight: bold; text-anchor: middle;" class="figure-text">FiLM generator</text></g><g class="figure-faded"><path d="M 296 298 L 335 298" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(335, 298)" class="figure-path"></use><path d="M 760 298 L 789 298" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(789, 298)" class="figure-path"></use><path d="M 730 96 L 730 233" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(730, 233)" class="figure-path"></use></g><path d="M 296 48 L 335 48" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(335, 48)" class="figure-path"></use><path d="M 485 96 L 485 233" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(485, 233)" class="figure-path"></use><path d="M 665 96 L 665 233" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(665, 233)" class="figure-path"></use><text x="340" y="106" dy="1em" class="figure-text">FiLM parameters</text><image x="200" y="250" width="96" height="96" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/tuebingen_neckarfront.jpg"></image><g transform="translate(240, -50)"><g transform="translate(100, 288)"><rect width="60" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="30" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 30, 60)" class="figure-text figure-text-faded">sub-network</text></g><g class="figure-faded"><path d="M 160 348 L 175 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(175, 348)" class="figure-path"></use></g><g transform="translate(180, 288)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="15" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text figure-text-faded">normalization</text></g><g class="figure-faded"><path d="M 210 348 L 225 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(225, 348)" class="figure-path"></use></g><g transform="translate(230, 288)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="font-weight: bold; text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">FiLM layer</text></g><g class="figure-faded"><path d="M 260 348 L 275 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(275, 348)" class="figure-path"></use></g><g transform="translate(280, 288)"><rect width="60" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="30" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 30, 60)" class="figure-text figure-text-faded">sub-network</text></g><g class="figure-faded"><path d="M 340 348 L 355 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(355, 348)" class="figure-path"></use></g><g transform="translate(360, 288)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="15" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text figure-text-faded">normalization</text></g><g class="figure-faded"><path d="M 390 348 L 405 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(405, 348)" class="figure-path"></use></g><g transform="translate(410, 288)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="font-weight: bold; text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">FiLM layer</text></g><g class="figure-faded"><path d="M 440 348 L 455 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(455, 348)" class="figure-path"></use></g><g transform="translate(460, 288)"><rect width="60" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="30" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 30, 60)" class="figure-text figure-text-faded">...</text></g><path d="M 175 410 L 175 420 L 265 420 L 265 410" style="stroke-width: 1px;" class="figure-line"></path><text x="175" y="420" dy="1.5em" class="figure-text"><tspan> conditional instance </tspan><tspan x="175" dy="1.5em"> normalization </tspan></text><path d="M 355 410 L 355 420 L 445 420 L 445 410" style="stroke-width: 1px;" class="figure-line"></path><text x="355" y="420" dy="1.5em" class="figure-text"><tspan> conditional instance </tspan><tspan x="355" dy="1.5em"> normalization </tspan></text><image x="554" y="300" width="96" height="96" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/tuebingen_neckarfront_cassis_cap_lombard_opus_196.jpg"></image></g></g></g></svg>
  </figure>
  <p class="content" content-name="style-transfer" content-type="literature">
    Dumoulin et al. <d-cite key="dumoulin2017learned"></d-cite> use a simple
    embedding lookup to produce instance normalization parameters, while
    Ghiasi et al. <d-cite key="ghiasi2017exploring"></d-cite> further
    introduce a <em>style prediction network</em>, trained jointly with the
    style transfer network to predict the conditioning parameters directly from
    a given style image. In this article we opt to use the FiLM nomenclature
    because it is decoupled from normalization operations, but the FiLM
    layers used by Perez et al. <d-cite key="perez2018film"></d-cite> were
    themselves heavily inspired by the conditional normalization layers used
    by Dumoulin et al. <d-cite key="dumoulin2017learned"></d-cite>.
  </p>
  <p class="content" content-name="style-transfer" content-type="literature">
    Yang et al. <d-cite key="yang2018efficient"></d-cite> use a related
    architecture for video object segmentation &mdash; the task of segmenting a
    particular object throughout a video given that object's segmentation in the
    first frame. Their model conditions an image segmentation network over a
    video frame on the provided first frame segmentation using feature-wise
    scaling factors, as well as on the previous frame using position-wise
    biases.
  </p>
  <p class="content" content-name="style-transfer" content-type="literature">
    So far, the models we covered have two sub-networks: a primary
    network in which feature-wise transformations are applied and a secondary
    network which outputs parameters for these transformations. However, this
    distinction between <em>FiLM-ed network</em> and <em>FiLM generator</em>
    is not strictly necessary. As an example, Huang and Belongie
    <d-cite key="huang2017arbitrary"></d-cite> propose an alternative
    style transfer network that uses adaptive instance normalization layers,
    which compute normalization parameters using a simple heuristic.
  </p>
  <figure class="content l-body-outset" content-name="style-transfer" id="adain-diagram" content-type="literature">
    <svg viewBox="0 0 888 570" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><g transform="translate(60, 160)"><text x="200" y="-150" dy="1em" class="figure-text"><tspan> The model processes </tspan><tspan x="200" dy="1.5em"> content and style images </tspan><tspan x="200" dy="1.5em"> up to the adaptive instance </tspan><tspan x="200" dy="1.5em"> normalization layer. </tspan></text><text x="380" y="-150" dy="1em" class="figure-text"><tspan> FiLM parameters are </tspan><tspan x="380" dy="1.5em"> computed as the spatial </tspan><tspan x="380" dy="1.5em"> mean and standard </tspan><tspan x="380" dy="1.5em"> deviation statistics of the </tspan><tspan x="380" dy="1.5em"> style feature maps. </tspan></text><text x="550" y="-150" dy="1em" class="figure-text"><tspan> The FiLM-ed feature maps </tspan><tspan x="550" dy="1.5em"> are fed to the remainder </tspan><tspan x="550" dy="1.5em"> of the network to produce </tspan><tspan x="550" dy="1.5em"> the stylized image. </tspan></text><image x="0" y="0" width="96" height="96" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/cassis_cap_lombard_opus_196.jpg"></image><image x="0" y="250" width="96" height="96" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/tuebingen_neckarfront.jpg"></image><g class="figure-faded"><path d="M 96 298 L 195 298" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(195, 298)" class="figure-path"></use></g><g transform="translate(200, -50)"><g class="figure-faded"><path d="M -104 98 L -5 98" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(-5, 98)" class="figure-path"></use></g><g transform="translate(0, 38)"><rect width="90" height="120" class="figure-film-generator figure-element figure-box figure-faded"></rect><text x="45" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 45, 60)" class="figure-text figure-text-faded">sub-network</text></g><line stroke-dasharray="5,5" x1="45" y1="160" x2="45" y2="288" class="figure-line"></line><g transform="translate(0, 288)"><rect width="90" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="45" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 45, 60)" class="figure-text figure-text-faded">sub-network</text></g><g class="figure-faded"><path d="M 90 98 L 175 98" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(175, 98)" class="figure-path"></use></g><g transform="translate(180, 38)"><rect width="90" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="45" y="60" dy="-0.5em" style="text-anchor: middle;" transform="rotate(-90, 45, 60)" class="figure-text"><tspan style="font-family: serif;">, </tspan><tspan> across</tspan><tspan x="45" dy="1.5em">spatial axes</tspan></text></g><path d="M 255 158 L 255 283" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(255, 283)" class="figure-path"></use><text x="250" y="200" dy="1.5em" style="text-anchor: end;" class="figure-text">FiLM</text><text x="250" y="215" dy="1.5em" style="text-anchor: end;" class="figure-text">parameters</text><g class="figure-faded"><path d="M 90 348 L 175 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(175, 348)" class="figure-path"></use></g><g transform="translate(180, 288)"><rect width="35" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="17.5" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 17.5, 60)" class="figure-text figure-text-faded">normalization</text></g><g class="figure-faded"><path d="M 215 348 L 230 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(230, 348)" class="figure-path"></use></g><g transform="translate(235, 288)"><rect width="35" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="17.5" y="60" dy="0.4em" style="font-weight: bold; text-anchor: middle;" transform="rotate(-90, 17.5, 60)" class="figure-text">FiLM layer</text></g><g class="figure-faded"><path d="M 270 348 L 345 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(345, 348)" class="figure-path"></use></g><path d="M 175 410 L 175 420 L 275 420 L 275 410" style="stroke-width: 1px;" class="figure-line"></path><text x="175" y="420" dy="1.5em" class="figure-text"><tspan> adaptive instance </tspan><tspan x="175" dy="1.5em"> normalization </tspan></text><g transform="translate(350, 288)"><rect width="90" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="45" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 45, 60)" class="figure-text figure-text-faded">sub-network</text></g><g class="figure-faded"><path d="M 440 348 L 525 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(525, 348)" class="figure-path"></use></g><image x="530" y="300" width="96" height="96" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/tuebingen_neckarfront_cassis_cap_lombard_opus_196.jpg"></image></g></g></svg>
  </figure>
  <p class="content" content-name="style-transfer" content-type="literature">
    Adaptive instance normalization can be interpreted as inserting a FiLM
    layer midway through the model. However, rather than relying
    on a secondary network to predict the FiLM parameters from the style
    image, the main network itself is used to extract the style features
    used to compute FiLM parameters. Therefore, the model can be seen as
    <em>both</em> the FiLM-ed network and the FiLM generator.
  </p>
  <button class="collapsible" content-name="image-recognition" content-type="literature">Image recognition<span style="float: right;">+</span></button>
  <p class="content" content-name="image-recognition" content-type="literature">
    As discussed in previous subsections, there is nothing preventing us from considering a
    neural network's activations <em>themselves</em> as conditioning
    information. This idea gives rise to
    <em>self-conditioned</em> models.
  </p>
  <figure class="content l-body" content-name="image-recognition" content-type="literature">
    <svg viewBox="0 0 704 340" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><text x="10" y="10" dy="1em" class="figure-text"><tspan> The FiLM generator predicts FiLM </tspan><tspan x="10" dy="1.5em"> parameters conditioned on the </tspan><tspan x="10" dy="1.5em"> network&#x27;s internal activations. </tspan></text><text x="10" y="200" dy="1em" class="figure-text"><tspan> An arbitrary input vector (or feature map) </tspan><tspan x="10" dy="1.5em"> modulates downstream activations. </tspan></text><g transform="translate(260,200)"><rect x="0" y="0" width="100" height="100" class="figure-filmed-network figure-element figure-box"></rect><text x="10" y="10" dy="0.4em" class="figure-text">input</text></g><path d="M 360 250 L 408 250" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(408, 250)" class="figure-path"></use><path d="M 360 250 L 374 250 a 6 6 0 0 0 6 -6 L 380 76 a 6 6 0 0 1 6 -6 L 408 70" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(408, 70)" class="figure-path"></use><g transform="translate(413, 190)"><rect x="0" y="0" width="50" height="120" class="figure-faded figure-filmed-network figure-element figure-box"></rect><text x="25" y="60" dy="0.4em" transform="rotate(-90,25,60)" style="text-anchor: middle;" class="figure-text figure-text-faded">sub-network</text></g><path d="M 463 250 L 511 250" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(511, 250)" class="figure-path"></use><g transform="translate(516, 190)"><rect x="0" y="0" width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" transform="rotate(-90,15,60)" style="text-anchor: middle;" class="figure-text">FiLM layer</text></g><path d="M 546 250 L 595 250" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(595, 250)" class="figure-path"></use><g transform="translate(413, 10)"><rect width="50" height="120" class="figure-film-generator figure-element figure-box" x="0" y="0"></rect><text x="25" y="65" transform="rotate(-90,25,60)" style="text-anchor: middle;" class="figure-text">FiLM generator</text></g><path d="M 463 70 L 525 70 a 6 6 0 0 1 6 6 L 531 185" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(531, 185)" class="figure-path"></use><g transform="translate(600,200)"><rect x="0" y="0" width="100" height="100" class="figure-filmed-network figure-element figure-box"></rect><text x="10" y="10" dy="0.4em" class="figure-text">output</text></g></svg>
  </figure>
  <p class="content" content-name="image-recognition" content-type="literature">
    Highway Networks <d-cite key="srivastava2015highway"></d-cite> are a prime
    example of applying this self-conditioning principle. They take inspiration
    from the LSTMs' <d-cite key="hochreiter1997long"></d-cite> heavy use of
    feature-wise sigmoidal gating in their input, forget, and output gates to
    regulate information flow:
  </p>
  <figure class="content l-body" content-name="image-recognition" content-type="literature">
    <svg viewBox="0 0 704 380" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-up" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path></defs><g transform="translate(10, 10)"><text x="0" y="180" dy="0.4em" class="figure-text">input</text><g transform="translate(40, 140)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use></g><path d="M 65 180 L 285 180" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(285, 180)" class="figure-path"></use><path d="M 65 180 C 115 180 65 50 115 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(115, 60)" class="figure-path"></use><path d="M 65 180 C 115 180 65 310 115 300" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(115, 300)" class="figure-path"></use><g transform="translate(120, 0)"><rect width="40" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">sub-network</text></g><path d="M 160 60 L 215 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(215, 60)" class="figure-path"></use><g transform="translate(220, 20)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-film-generator figure-element"></use></g><path d="M 245 60 L 345 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(345, 60)" class="figure-path"></use><g transform="translate(120, 240)"><rect width="40" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">sigmoidal layer</text></g><path d="M 160 300 L 215 300" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(215, 300)" class="figure-path"></use><g transform="translate(220, 260)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-film-generator figure-element"></use></g><path d="M 245 300 L 294 300 a 6 6 0 0 0 6 -6 L 300 195" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(300, 195)" class="figure-path"></use><path d="M 245 300 L 354 300 a 6 6 0 0 0 6 -6 L 360 185" class="figure-line"></path><path d="M 360 175 L 360 150" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(360, 150)" class="figure-path"></use><g transform="translate(330, 115)"><rect width="60" height="30" class="figure-element figure-box"></rect><text x="30" y="15" dy="0.4em" style="text-anchor: middle;" class="figure-text">1 - x</text></g><path d="M 360 115 L 360 75" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(360, 75)" class="figure-path"></use><g transform="translate(300, 180)"><circle r="10" class="figure-element"></circle><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 310 180 L 405 180" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(405, 180)" class="figure-path"></use><g transform="translate(360, 60)"><circle r="10" class="figure-element"></circle><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 370 60 L 414 60 a 6 6 0 0 1 6 6 L 420 165" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(420, 165)" class="figure-path"></use><g transform="translate(420, 180)"><circle r="10" class="figure-element"></circle><path d="M -5 0 L 5 0" class="figure-line"></path><path d="M 0 -5 L 0 5" class="figure-line"></path></g><path d="M 430 180 L 535 180" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(535, 180)" class="figure-path"></use><g transform="translate(540, 140)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use></g><text x="570" y="180" dy="0.4em" class="figure-text">output</text></g></svg>
  </figure>
  <p class="content" content-name="image-recognition" content-type="literature">
    The ImageNet 2017 winning model <d-cite key="hu2017squeeze"></d-cite> also
    employs feature-wise sigmoidal gating in a self-conditioning manner, as a
    way to "recalibrate" a layer's activations conditioned on themselves.
  </p>
  <figure class="content l-body" content-name="image-recognition" content-type="literature">
    <svg viewBox="0 0 704 340" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path></defs><text x="10" y="10" dy="1em" class="figure-text"><tspan> The <tspan style="font-style: italic;">squeeze-and-excitation</tspan> block </tspan><tspan x="10" dy="1.5em"> uses <tspan style="font-weight: bold;">sigmoidal gating</tspan>. First, the </tspan><tspan x="10" dy="1.5em"> network maps input feature maps </tspan><tspan x="10" dy="1.5em"> to a gating vector. </tspan></text><text x="260" y="220" dy="1em" class="figure-text"><tspan> The gating vector is then multiplied </tspan><tspan x="260" dy="1.5em"> with the input feature maps. </tspan></text><g transform="translate(-190, 10)"><g transform="translate(284, 200)"><rect x="0" y="0" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="10" y="10" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="20" y="20" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="30" dy="0.4em" class="figure-text">input</text></g><path d="M 404 260 L 660 260" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(660, 260)" class="figure-path"></use><g transform="translate(675, 260)"><circle r="10" class="figure-element"></circle><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 685 260 L 765 260" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(765, 260)" class="figure-path"></use><g transform="translate(770, 200)"><rect x="0" y="0" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="10" y="10" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="20" y="20" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="30" dy="0.4em" class="figure-text">output</text></g><path d="M 404 260 L 428 260 a 6 6 0 0 0 6 -6 L 434 66 a 6 6 0 0 1 6 -6 L 450 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(450, 60)" class="figure-path"></use><g transform="translate(455, 0)"><rect width="40" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">global pooling</text></g><path d="M 495 60 L 520 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(520, 60)" class="figure-path"></use><g transform="translate(525, 0)"><rect width="40" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">ReLU layer</text></g><path d="M 565 60 L 590 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(590, 60)" class="figure-path"></use><g transform="translate(595, 0)"><rect width="40" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">sigmoidal layer</text></g><path d="M 635 60 L 660 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(660, 60)" class="figure-path"></use><g transform="translate(665, 30)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-film-generator figure-element"></use></g><path d="M 675 90 L 675 245" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(675, 245)" class="figure-path"></use></g></svg>
  </figure>
  <button class="collapsible" content-name="nlp" content-type="literature">Natural language processing<span style="float: right;">+</span></button>
  <p class="content" content-name="nlp" content-type="literature">
    For statistical language modeling (i.e., predicting the next word
    in a sentence), the LSTM <d-cite key="hochreiter1997long,melis2017lstm"></d-cite>
    constitutes a popular class of recurrent network architectures. The LSTM
    relies heavily on feature-wise sigmoidal gating to control the
    information flow in and out of the memory or context cell
    <d-math>\mathbf{c}</d-math>, based on the hidden states
    <d-math>\mathbf{h}</d-math> and inputs <d-math>\mathbf{x}</d-math> at
    every timestep <d-math>\mathbf{t}</d-math>.
  </p>
  <figure class="content l-body" content-name="nlp" content-type="literature">
    <svg viewBox="0 0 704 360" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-up" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><g transform="translate(50, 0)"><g transform="translate(20, -60)"><text x="0" y="95" dy="0.4em" class="figure-text"><tspan style="font-weight: bold;">c</tspan><tspan dy="5px" class="subscript">t-1</tspan></text><g transform="translate(30, 65)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use></g><g><path d="M 50 95 L 178 95" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(178, 95)" class="figure-path"></use><g transform="translate(193, 95)"><ellipse cx="0" cy="0" rx="10" ry="10" class="figure-element"></ellipse><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 203 95 L 368 95" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(368, 95)" class="figure-path"></use><g transform="translate(383, 95)"><ellipse rx="10" ry="10" class="figure-element"></ellipse><line x1="0" y1="-5" x2="0" y2="5" class="figure-line"></line><line x1="-5" y1="0" x2="5" y2="0" class="figure-line"></line></g><path d="M 393 95 L 472 95 A 6 6 0 0 1 478 101 L 478 119" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(478, 119)" class="figure-path"></use></g><g transform="translate(478, 133)"><rect x="-30" y="-10" width="60" height="20" class="figure-box figure-element"></rect><text dy="0.4em" style="text-anchor: middle;" class="figure-text">tanh</text></g><g><path d="M 460 95 L 530 95" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(530, 95)" class="figure-path"></use></g><g transform="translate(535, 65)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use></g><text x="565" y="95" dy="0.4em" class="figure-text"><tspan style="font-weight: bold;">c</tspan><tspan dy="5px" class="subscript">t</tspan></text><g><path d="M 488 175 L 530 175" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(530, 175)" class="figure-path"></use></g><g transform="translate(535, 145)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use></g><text x="565" y="175" dy="0.4em" class="figure-text"><tspan style="font-weight: bold;">h</tspan><tspan dy="5px" class="subscript">t</tspan></text><g><path d="M 383 110 L 383 165" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(383, 110)" class="figure-path"></use><g transform="translate(383, 175)"><ellipse cx="0" cy="0" rx="10" ry="10" class="figure-element"></ellipse><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 478 143 L 478 160" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(478, 160)" class="figure-path"></use><g transform="translate(478, 175)"><ellipse cx="0" cy="0" rx="10" ry="10" class="figure-element"></ellipse><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 193 215 L 193 110" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(193, 110)" class="figure-path"></use></g><g transform="translate(193, 225)"><rect x="-30" y="-10" width="60" height="20" class="figure-box figure-element"></rect><text dy="0.4em" style="text-anchor: middle;" class="figure-text">sigmoid</text></g><g><path d="M 288 215 L 288 181 A 6 6 0 0 1 294 175 L 368 175" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(368, 175)" class="figure-path"></use></g><g transform="translate(288, 225)"><rect x="-30" y="-10" width="60" height="20" class="figure-box figure-element"></rect><text dy="0.4em" style="text-anchor: middle;" class="figure-text">sigmoid</text></g><g><path d="M 383 215 L 383 190" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(383, 190)" class="figure-path"></use></g><g transform="translate(383, 225)"><rect x="-30" y="-10" width="60" height="20" class="figure-box figure-element"></rect><text dy="0.4em" style="text-anchor: middle;" class="figure-text">tanh</text></g><g><path d="M 478 215 L 478 190" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(478, 190)" class="figure-path"></use></g><g transform="translate(478, 225)"><rect x="-30" y="-10" width="60" height="20" class="figure-box figure-element"></rect><text dy="0.4em" style="text-anchor: middle;" class="figure-text">sigmoid</text></g><g><path d="M 193 257 L 193 240" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(193, 240)" class="figure-path"></use></g><g transform="translate(159, 257)"><rect width="70" height="40" class="figure-element figure-box figure-film-generator "></rect><text x="35" y="20" dy="0.4em" style="text-anchor: middle;" class="figure-text">linear</text></g><g><path d="M 288 257 L 288 240" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(288, 240)" class="figure-path"></use></g><g transform="translate(254, 257)"><rect width="70" height="40" class="figure-element figure-box figure-film-generator"></rect><text x="35" y="20" dy="0.4em" style="text-anchor: middle;" class="figure-text">linear</text></g><g><path d="M 383 257 L 383 240" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(383, 240)" class="figure-path"></use></g><g transform="translate(349, 257)"><rect width="70" height="40" class="figure-element figure-box figure-film-generator"></rect><text x="35" y="20" dy="0.4em" style="text-anchor: middle;" class="figure-text">linear</text></g><g><path d="M 478 257 L 478 240" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(478, 240)" class="figure-path"></use></g><g transform="translate(444, 257)"><rect width="70" height="40" class="figure-element figure-box figure-film-generator"></rect><text x="35" y="20" dy="0.4em" style="text-anchor: middle;" class="figure-text">linear</text></g><g transform="translate(30, 300)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use></g><text x="0" y="330" dy="0.4em" class="figure-text"><tspan style="font-weight: bold;">h</tspan><tspan dy="5px" class="subscript">t-1</tspan></text><path d="M 50 330 L 75 330" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(75, 330)" class="figure-path"></use><path d="M 100 330 L 187 330 A 6 6 0 0 0 193 324 L 193 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(193, 302)" class="figure-path"></use><path d="M 100 330 L 282 330 A 6 6 0 0 0 288 324 L 288 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(288, 302)" class="figure-path"></use><path d="M 100 330 L 377 330 A 6 6 0 0 0 383 324 L 383 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(383, 302)" class="figure-path"></use><path d="M 100 330 L 472 330 A 6 6 0 0 0 478 324 L 478 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(478, 302)" class="figure-path"></use><text x="50" y="400" dy="0.4em" style="text-anchor: middle;" class="figure-text"><tspan style="font-weight: bold;">x</tspan><tspan dy="5px" class="subscript">t</tspan></text><g transform="translate(60, 390)"><use xlink:href="#row-left" transform="translate(0, 0)" class="figure-element figure-film-generator"></use><use xlink:href="#row-middle" transform="translate(20, 0)" class="figure-element figure-film-generator"></use><use xlink:href="#row-right" transform="translate(40, 0)" class="figure-element figure-film-generator"></use></g><g transform="translate(80, 290)"><rect x="0" y="0" width="20" height="80" class="figure-element figure-box"></rect><text x="10" y="40" dy="0.4em" transform="rotate(-90,10,40)" style="text-anchor: middle;" class="figure-text">concatenate</text></g><path d="M 90 390 L 90 375" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(90, 375)" class="figure-path"></use></g></g></svg>
  </figure>

  <p class="content" content-name="nlp" content-type="literature">
    Also in the domain of language modeling, Dauphin et al. <d-cite key="dauphin2017language"></d-cite> use sigmoidal
    gating in their proposed <em>gated linear unit</em>, which uses half of the
    input features to apply feature-wise sigmoidal gating to the other half.
    Gehring et al.  <d-cite key="gehring2017convolutional"></d-cite> adopt this
    architectural feature, introducing a fast, parallelizable model for machine
    translation in the form of a fully convolutional network.
  </p>
  <figure class="content l-body" content-name="nlp" content-type="literature">
    <svg viewBox="0 0 704 260" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-up" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path></defs><text x="380" y="10" dy="1em" class="figure-text"><tspan> The <tspan style="font-style: italic;">gated linear unit</tspan> activation function </tspan><tspan x="380" dy="1.5em"> uses <tspan style="font-weight: bold;">sigmoidal gating</tspan>. Half of the input </tspan><tspan x="380" dy="1.5em"> features go through a sigmoid function </tspan><tspan x="380" dy="1.5em"> to produce a gating vector. </tspan></text><text x="380" y="170" dy="1em" class="figure-text"><tspan> The gating vector is then multiplied </tspan><tspan x="380" dy="1.5em"> with the second half of the features. </tspan></text><g transform="translate(10, 10)"><text x="0" y="177.5" dy="0.4em" style="text-anchor: begin;" class="figure-text">input</text><g transform="translate(40, 120)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#row-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#row-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#row-middle" transform="translate(0, 60)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-middle" transform="translate(0, 80)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 100)" class="figure-filmed-network figure-element"></use></g><path d="M 60 210 L 319 210" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(319, 210)" class="figure-path"></use><g transform="translate(334, 210)"><circle r="10" class="figure-element"></circle><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 345 210 L 600 210" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(600, 210)" class="figure-path"></use><path d="M 60 150 L 130 150 a 6 6 0 0 0 6 -6 L 136 66 a 6 6 0 0 1 6 -6 L 200 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(200, 60)" class="figure-path"></use><g transform="translate(205, 0)"><rect width="40" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">sigmoid</text></g><path d="M 245 60 L 319 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(319, 60)" class="figure-path"></use><g transform="translate(324, 30)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#row-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-film-generator figure-element"></use></g><path d="M 334 90 L 334 195" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(334, 195)" class="figure-path"></use><g transform="translate(605, 180)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use></g><text x="630" y="210" dy="0.4em" style="text-anchor: begin;" class="figure-text">output</text></g></svg>
  </figure>
  <p class="content" content-name="nlp" content-type="literature">
    The Gated-Attention Reader <d-cite key="dhingra2017gated"></d-cite>
    uses feature-wise scaling, extracting information
    from text by conditioning a document-reading network on a query. Its
    architecture consists of multiple Gated-Attention modules, which involve
    element-wise multiplications between document representation tokens and
    token-specific query representations extracted via soft attention on the
    query representation tokens.
  </p>
  <figure class="content l-body" content-name="nlp" content-type="literature">
    <svg viewBox="0 0 704 340" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-up" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path></defs><text x="10" y="10" dy="1em" class="figure-text"><tspan> Dhingra et al. use <tspan style="font-weight: bold;">conditional scaling</tspan> to </tspan><tspan x="10" dy="1.5em"> integrate query information into a document </tspan><tspan x="10" dy="1.5em"> processing network. Applying soft attention </tspan><tspan x="10" dy="1.5em"> to the <tspan style="font-weight: bold;">query representation tokens</tspan></tspan><tspan x="10" dy="1.5em"></tspan><tspan x="10" dy="1.5em"> produces the scaling vector. </tspan></text><text x="10" y="210" dy="1em" class="figure-text"><tspan> The scaling vector is then multiplied with </tspan><tspan x="10" dy="1.5em"> the input <tspan style="font-weight: bold;">document representation token</tspan></tspan></text><g transform="translate(0, 10)"><text x="284" y="200" dy="-1.5em" style="font-weight: bold;" class="figure-text"><tspan>document</tspan><tspan x="284" dy="1.5em">representation</tspan><tspan x="284" dy="1.5em">token</tspan></text><g transform="translate(284, 230)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use></g><path d="M 304 260 L 488 260" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(488, 260)" class="figure-path"></use><path d="M 304 260 L 428 260 A 6 6 0 0 0 434 254 L 434 125" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(434, 125)" class="figure-path"></use><g transform="translate(504, 260)"><circle r="10" class="figure-element"></circle><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 514 260 L 599 260" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(599, 260)" class="figure-path"></use><text x="604" y="200" style="font-weight: bold;" class="figure-text"><tspan>output</tspan><tspan x="604" dy="1.5em">token</tspan></text><g transform="translate(604, 230)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-filmed-network figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-filmed-network figure-element"></use></g><text x="284" y="60" dy="-1.5em" style="font-weight: bold;" class="figure-text"><tspan>query</tspan><tspan x="284" dy="1.5em">representation</tspan><tspan x="284" dy="1.5em">tokens</tspan></text><g transform="translate(414, 0)"><rect width="40" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">soft attention</text></g><g transform="translate(494, 30)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-film-generator figure-element"></use></g><path d="M 380 60 L 409 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(409, 60)" class="figure-path"></use><path d="M 455 60 L 489 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(489, 60)" class="figure-path"></use><path d="M 504 90 L 504 245" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(504, 245)" class="figure-path"></use></g></svg>
  </figure>

  <button class="collapsible" content-name="reinforcement-learning" content-type="literature">Reinforcement learning<span style="float: right;">+</span></button>
  <p class="content" content-name="reinforcement-learning" content-type="literature">
    The Gated-Attention architecture <d-cite key="chaplot2017gated"></d-cite>
    uses feature-wise sigmoidal gating to fuse linguistic and visual
    information in an agent trained to follow simple "go-to" language
    instructions in the VizDoom <d-cite key="kempa2016vizdoom"></d-cite> 3D
    environment.
  </p>
  <figure class="content l-body" content-name="reinforcement-learning" content-type="literature">
    <svg viewBox="0 0 704 340" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path></defs><text x="10" y="10" dy="1em" class="figure-text"><tspan> Chaplot et al. use <tspan style="font-weight: bold;">sigmoidal gating</tspan></tspan><tspan x="10" dy="1.5em"> as a multimodal fusion mechanism. </tspan><tspan x="10" dy="1.5em"> An instruction representation is mapped </tspan><tspan x="10" dy="1.5em"> to a scaling vector via a sigmoid layer. </tspan></text><text x="10" y="210" dy="1em" class="figure-text"><tspan> The scaling vector is then multiplied with </tspan><tspan x="10" dy="1.5em"> the input feature maps. A policy network </tspan><tspan x="10" dy="1.5em"> uses the result to decide the next action. </tspan></text><g transform="translate(-30, 10)"><g transform="translate(284, 200)"><rect x="0" y="0" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="10" y="10" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="20" y="20" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="30" dy="0.4em" class="figure-text">input</text></g><path d="M 404 260 L 488 260" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(488, 260)" class="figure-path"></use><g transform="translate(504, 260)"><circle r="10" class="figure-element"></circle><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 514 260 L 599 260" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(599, 260)" class="figure-path"></use><g transform="translate(604, 200)"><rect x="0" y="0" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="10" y="10" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="20" y="20" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="30" dy="0.4em" class="figure-text">output</text></g><text x="284" y="60" dy="-0.5em" style="font-weight: bold;" class="figure-text"><tspan>instruction</tspan><tspan x="284" dy="1.5em">representation</tspan></text><g transform="translate(414, 0)"><rect width="40" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">sigmoid</text></g><g transform="translate(494, 30)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-film-generator figure-element"></use></g><path d="M 380 60 L 409 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(409, 60)" class="figure-path"></use><path d="M 455 60 L 489 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(489, 60)" class="figure-path"></use><path d="M 504 90 L 504 245" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(504, 245)" class="figure-path"></use></g></svg>
  </figure>
  <p class="content" content-name="reinforcement-learning" content-type="literature">
    Bahdanau et al.<d-cite key="bahdanau2018learning"></d-cite> use FiLM
    layers to condition Neural Module Network<d-cite key="andreas2016neural"></d-cite>
    and LSTM<d-cite key="hochreiter1997long"></d-cite> -based policies to follow
    basic, compositional language instructions (arranging objects and going
    to particular locations) in a 2D grid world. They train this policy
    in an adversarial manner using rewards from another FiLM-based network,
    trained to discriminate between ground-truth examples of achieved
    instruction states and failed policy trajectories states.
  </p>
  <p class="content" content-name="reinforcement-learning" content-type="literature">
    Outside instruction-following, Kirkpatrick et al.
    <d-cite key="kirkpatrick2017overcoming"></d-cite> also use
    game-specific scaling and biasing to condition a shared policy network
    trained to play 10 different Atari games.
  </p>
  <button class="collapsible" content-name="generative-modeling" content-type="literature">Generative modeling<span style="float: right;">+</span></button>
  <p class="content" content-name="generative-modeling" content-type="literature">
    The conditional variant of DCGAN <d-cite key="radford2016unsupervised"></d-cite>,
    a well-recognized network architecture for generative adversarial networks
    <d-cite key="goodfellow2014generative"></d-cite>, uses concatenation-based
    conditioning. The class label is broadcasted as a feature map and then
    concatenated to the input of convolutional and transposed convolutional
    layers in the discriminator and generator networks.
  </p>
  <figure class="content l-body" content-name="generative-modeling" content-type="literature">
    <svg viewBox="0 0 704 400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><path d="M475,10l0,360" style="stroke-width: 1px; stroke: #666; opacity: 0.5"></path><text x="10" y="10" class="figure-text"><tspan><tspan style="font-weight: bold;">Concatenation-based conditioning</tspan> is used in the class-conditional </tspan><tspan x="10" dy="1.5em"> DCGAN model. Each convolutional layer is concatenated with the </tspan><tspan x="10" dy="1.5em"> broadcased label along the channel axis. </tspan></text><text x="495" y="10" class="figure-text"><tspan> The resulting stack of feature maps </tspan><tspan x="495" dy="1.5em"> is then <tspan style="font-weight: bold;">convolved</tspan> to produce the </tspan><tspan x="495" dy="1.5em"> conditioned output. </tspan></text><g transform="translate(10, 180)"><g transform="translate(0, 30)"><rect x="0" y="0" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="10" y="10" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="20" y="20" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="30" dy="0.4em" class="figure-text">input</text></g><g transform="translate(191, 30)"><rect width="40" height="120" class="figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">concatenate</text></g><g transform="translate(302, 30)"><rect x="0" y="0" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="10" y="10" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="20" y="20" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="30" dy="0.4em" class="figure-text">input</text><rect x="40" y="40" width="100" height="100" style="fill-opacity: 1;" class="figure-film-generator figure-element figure-box"></rect><text x="50" y="50" dy="0.4em" class="figure-text">class label</text></g><g transform="translate(493, 30)"><rect width="40" height="120" class="figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">convolution</text></g><g transform="translate(564, 30)"><rect x="0" y="0" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="10" y="10" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="20" y="20" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="30" dy="0.4em" class="figure-text">output</text></g><path d="M 120 90 L 186 90" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(186, 90)" class="figure-path"></use><path d="M 231 90 L 297 90" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(297, 90)" class="figure-path"></use><path d="M 442 90 L 488 90" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(488, 90)" class="figure-path"></use><path d="M 533 90 L 559 90" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(559, 90)" class="figure-path"></use><path d="M 211 -50 L 211 25" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(211, 25)" class="figure-path"></use><text x="211" y="10" dy="-0.4em" transform="rotate(-90, 211, 10)" class="figure-text">broadcast</text><text x="211" y="-60" dy="-0.4em" style="text-anchor: middle; font-weight: bold;" class="figure-text">class label</text></g></svg>
  </figure>
  <p class="content" content-name="generative-modeling" content-type="literature">
    For convolutional layers, concatenation-based conditioning requires the
    network to learn redundant convolutional parameters to interpret each
    constant, conditioning feature map; as a result, directly applying a
    conditional bias is more parameter efficient, but the two approaches are
    still mathematically equivalent.
  </p>
  <p class="content" content-name="generative-modeling" content-type="literature">
    PixelCNN <d-cite key="oord2016conditional"></d-cite>
    and WaveNet <d-cite key="oord2016wavenet"></d-cite> &mdash; two recent
    advances in autoregressive, generative modeling of images and audio,
    respectively &mdash; use conditional biasing. The simplest form of
    conditioning in PixelCNN adds feature-wise biases to all convolutional layer
    outputs. In FiLM parlance, this operation is equivalent to inserting FiLM
    layers after each convolutional layer and setting the scaling coefficients
    to a constant value of 1.
    <d-footnote>
      The authors also describe a location-dependent biasing scheme which
      cannot be expressed in terms of FiLM layers due to the absence of the
      feature-wise property.
    </d-footnote>
  </p>
  <figure class="content l-body" content-name="generative-modeling" content-type="literature">
    <svg viewBox="0 0 704 340" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path></defs><text x="10" y="10" dy="1em" class="figure-text"><tspan> PixelCNN uses <tspan style="font-weight: bold;">conditional biasing</tspan>. </tspan><tspan x="10" dy="1.5em"> The model first maps a high-level </tspan><tspan x="10" dy="1.5em"> image description to a bias vector. </tspan></text><text x="10" y="210" dy="1em" class="figure-text"><tspan> Then, it adds the bias vector to </tspan><tspan x="10" dy="1.5em"> the input stack of feature maps </tspan><tspan x="10" dy="1.5em"> to condition convolutional layers. </tspan></text><g transform="translate(-30, 10)"><g transform="translate(284, 200)"><rect x="0" y="0" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="10" y="10" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="20" y="20" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="30" dy="0.4em" class="figure-text">input</text></g><path d="M 404 260 L 488 260" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(488, 260)" class="figure-path"></use><g transform="translate(504, 260)"><circle r="10" class="figure-element"></circle><path d="M -5 0 L 5 0" class="figure-line"></path><path d="M 0 -5 L 0 5" class="figure-line"></path></g><path d="M 514 260 L 599 260" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(599, 260)" class="figure-path"></use><g transform="translate(604, 200)"><rect x="0" y="0" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="10" y="10" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><rect x="20" y="20" width="100" height="100" style="fill-opacity: 1;" class="figure-filmed-network figure-element figure-box"></rect><text x="30" y="30" dy="0.4em" class="figure-text">output</text></g><text x="284" y="60" dy="-0.5em" style="font-weight: bold;" class="figure-text"><tspan>image</tspan><tspan x="284" dy="1.5em">description</tspan></text><g transform="translate(414, 0)"><rect width="40" height="120" class="figure-film-generator figure-element figure-box"></rect><text x="20" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 20, 60)" class="figure-text">linear</text></g><g transform="translate(494, 30)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-film-generator figure-element"></use></g><path d="M 370 60 L 409 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(409, 60)" class="figure-path"></use><path d="M 455 60 L 489 60" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(489, 60)" class="figure-path"></use><path d="M 504 90 L 504 245" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(504, 245)" class="figure-path"></use></g></svg>
  </figure>
  <p class="content" content-name="generative-modeling" content-type="literature">
    WaveNet describes two ways in which conditional biasing allows external
    information to modulate the audio or speech generation process based on
    conditioning input:
  </p>
  <ol class="content" content-name="generative-modeling" content-type="literature">
    <li>
      <strong>Global conditioning</strong> applies the same conditional bias
      to the whole generated sequence and is used e.g. to condition on speaker
      identity.
    </li>
    <li>
      <strong>Local conditioning</strong> applies a conditional bias which
      varies across time steps of the generated sequence and is used e.g. to
      let linguistic features in a text-to-speech model influence which sounds
      are produced.
    </li>
  </ol>
  <p class="content" content-name="generative-modeling" content-type="literature">
    As in PixelCNN, conditioning in WaveNet can be viewed as inserting FiLM
    layers after each convolutional layer. The main difference lies in how
    the FiLM-generating network is defined: global conditioning
    expresses the FiLM-generating network as an embedding lookup which is
    broadcasted to the whole time series, whereas local conditioning expresses
    it as a mapping from an input sequence of conditioning information to an
    output sequence of FiLM parameters.
  </p>
  <button class="collapsible" content-name="speech-recognition" content-type="literature">Speech recognition<span style="float: right;">+</span></button>
  <p class="content" content-name="speech-recognition" content-type="literature">
    Kim et al.<d-cite key="kim2017dynamic"></d-cite> modulate a deep
    bidirectional LSTM using a form
    of conditional normalization. As discussed in the
    <em>Visual question-answering</em> and <em>Style transfer</em> subsections,
    conditional normalization can be seen as an instance of FiLM where
    the post-normalization feature-wise affine transformation is replaced
    with a FiLM layer.
  </p>
  <figure class="content l-body-outset" content-name="speech-recognition" content-type="literature">
    <svg viewBox="0 0 888 410" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-up" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><g transform="translate(-10, 0)"><text x="74" y="350" dy="1em" class="figure-text"><tspan> Kim et al. achieve speaker adaptation by adapting the usual </tspan><tspan x="74" dy="1.5em"> LSTM architecture to condition its various gates on an </tspan><tspan x="74" dy="1.5em" style="font-weight: bold;"> utterance summarization. </tspan></text><g transform="translate(20, -60)"><text x="0" y="80" dy="0.4em" class="figure-text figure-text-faded"><tspan style="font-weight: bold;">c</tspan><tspan dy="5px" class="subscript">t-1</tspan></text><g class="figure-faded"><path d="M 20 80 L 78 80" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(78, 80)" class="figure-path"></use><g transform="translate(93, 80)"><ellipse cx="0" cy="0" rx="10" ry="10" class="figure-element"></ellipse><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 103 80 L 268 80" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(268, 80)" class="figure-path"></use><g transform="translate(283, 80)"><ellipse rx="10" ry="10" class="figure-element"></ellipse><line x1="0" y1="-5" x2="0" y2="5" class="figure-line"></line><line x1="-5" y1="0" x2="5" y2="0" class="figure-line"></line></g><path d="M 293 80 L 372 80 A 6 6 0 0 1 378 86 L 378 103" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(378, 103)" class="figure-path"></use></g><g transform="translate(378, 118)"><rect x="-30" y="-10" width="60" height="20" class="figure-box figure-element figure-faded"></rect><text dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded">tanh</text></g><g class="figure-faded"><path d="M 375 80 L 430 80" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(430, 80)" class="figure-path"></use></g><text x="435" y="80" dy="0.4em" class="figure-text figure-text-faded"><tspan style="font-weight: bold;">c</tspan><tspan dy="5px" class="subscript">t</tspan></text><g class="figure-faded"><path d="M 388 175 L 430 175" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(430, 175)" class="figure-path"></use></g><text x="435" y="175" dy="0.4em" class="figure-text figure-text-faded"><tspan style="font-weight: bold;">h</tspan><tspan dy="5px" class="subscript">t</tspan></text><g class="figure-faded"><path d="M 283 95 L 283 165" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(283, 95)" class="figure-path"></use><g transform="translate(283, 175)"><ellipse cx="0" cy="0" rx="10" ry="10" class="figure-element"></ellipse><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 378 128 L 378 160" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(378, 160)" class="figure-path"></use><g transform="translate(378, 175)"><ellipse cx="0" cy="0" rx="10" ry="10" class="figure-element"></ellipse><ellipse rx="2" ry="2" class="figure-path"></ellipse></g><path d="M 93 215 L 93 95" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(93, 95)" class="figure-path"></use></g><g transform="translate(93, 225)"><rect x="-30" y="-10" width="60" height="20" class="figure-box figure-element figure-faded"></rect><text dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded">sigmoid</text></g><g class="figure-faded"><path d="M 188 215 L 188 181 A 6 6 0 0 1 194 175 L 268 175" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(268, 175)" class="figure-path"></use></g><g transform="translate(188, 225)"><rect x="-30" y="-10" width="60" height="20" class="figure-box figure-element figure-faded"></rect><text dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded">sigmoid</text></g><g class="figure-faded"><path d="M 283 215 L 283 190" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(283, 190)" class="figure-path"></use></g><g transform="translate(283, 225)"><rect x="-30" y="-10" width="60" height="20" class="figure-box figure-element figure-faded"></rect><text dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded">tanh</text></g><g class="figure-faded"><path d="M 378 215 L 378 190" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(378, 190)" class="figure-path"></use></g><g transform="translate(378, 225)"><rect x="-30" y="-10" width="60" height="20" class="figure-box figure-element figure-faded"></rect><text dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded">sigmoid</text></g><g class="figure-faded"><path d="M 93 257 L 93 240" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(93, 240)" class="figure-path"></use></g><g transform="translate(59, 257)"><rect width="70" height="40" class="figure-element figure-box"></rect><image x="3" y="2" width="63" height="36" style="clip-path: inset(0 0 0 0 round 3px);" xlink:href="images/dln_gate.png"></image></g><g class="figure-faded"><path d="M 188 257 L 188 240" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(188, 240)" class="figure-path"></use></g><g transform="translate(154, 257)"><rect width="70" height="40" class="figure-element figure-box"></rect><image x="3" y="2" width="63" height="36" style="clip-path: inset(0 0 0 0 round 3px);" xlink:href="images/dln_gate.png"></image></g><g class="figure-faded"><path d="M 283 257 L 283 240" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(283, 240)" class="figure-path"></use></g><g transform="translate(249, 257)"><rect width="70" height="40" class="figure-element figure-box"></rect><image x="3" y="2" width="63" height="36" style="clip-path: inset(0 0 0 0 round 3px);" xlink:href="images/dln_gate.png"></image></g><g class="figure-faded"><path d="M 378 257 L 378 240" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(378, 240)" class="figure-path"></use></g><g transform="translate(344, 257)"><rect width="70" height="40" class="figure-element figure-box"></rect><image x="3" y="2" width="63" height="36" style="clip-path: inset(0 0 0 0 round 3px);" xlink:href="images/dln_gate.png"></image></g><text x="0" y="376" dy="0.4em" class="figure-text figure-text-faded"><tspan style="font-weight: bold;">h</tspan><tspan dy="5px" class="subscript">t-1</tspan></text><g transform="translate(0, 337)"><text x="0" y="0" dy="-0.25em" style="font-weight: bold;" class="figure-text"><tspan> utterance </tspan><tspan x="0" dy="1.25em"> summarization </tspan></text></g><path d="M 20 376 L 60 376" class="figure-line figure-faded"></path><path d="M 30 357 C 30 365 30 376 50 376" class="figure-line"></path><g class="figure-faded"><path d="M 93 332 L 93 302" class="figure-line"></path><path d="M 93 332 C 93 302 108 332 108 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(93, 302)" class="figure-path"></use><use xlink:href="#arrow-up" transform="translate(108, 302)" class="figure-path"></use></g><path d="M 50 376 L 87 376 A 6 6 0 0 0 93 370 L 93 332 C 93 302 78 332 78 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(78, 302)" class="figure-path"></use><g class="figure-faded"><path d="M 188 332 L 188 302" class="figure-line"></path><path d="M 188 332 C 188 302 203 332 203 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(188, 302)" class="figure-path"></use><use xlink:href="#arrow-up" transform="translate(203, 302)" class="figure-path"></use></g><path d="M 50 376 L 182 376 A 6 6 0 0 0 188 370 L 188 332 C 188 302 173 332 173 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(173, 302)" class="figure-path"></use><g class="figure-faded"><path d="M 283 332 L 283 302" class="figure-line"></path><path d="M 283 332 C 283 302 298 332 298 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(283, 302)" class="figure-path"></use><use xlink:href="#arrow-up" transform="translate(298, 302)" class="figure-path"></use></g><path d="M 50 376 L 277 376 A 6 6 0 0 0 283 370 L 283 332 C 283 302 268 332 268 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(268, 302)" class="figure-path"></use><g class="figure-faded"><path d="M 378 332 L 378 302" class="figure-line"></path><path d="M 378 332 C 378 302 393 332 393 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(378, 302)" class="figure-path"></use><use xlink:href="#arrow-up" transform="translate(393, 302)" class="figure-path"></use></g><path d="M 50 376 L 372 376 A 6 6 0 0 0 378 370 L 378 332 C 378 302 363 332 363 302" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(363, 302)" class="figure-path"></use><path d="M 30 395 C 30 387 30 376 50 376" class="figure-line figure-faded"></path><text x="30" y="405" dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded"><tspan style="font-weight: bold;">x</tspan><tspan dy="5px" class="subscript">t</tspan></text></g><text x="540" y="350" dy="1em" class="figure-text"><tspan> Each gate uses FiLM to condition on the <tspan style="font-weight: bold;">utterance</tspan></tspan><tspan x="540" dy="1.5em"><tspan style="font-weight: bold;">summarization</tspan>. </tspan></text><g transform="translate(600, 40)"><rect x="-70" y="10" width="360" height="220" class="figure-box figure-element"></rect><path d="M -160 157 Q -130 110 -90 110" class="figure-line figure-dashed"></path><use xlink:href="#arrow-right" transform="translate(-80, 110)" style="fill: none;" class="figure-path"></use><g transform="translate(170, 30)" class="figure-faded"><ellipse rx="10" ry="10" class="figure-element"></ellipse><line x1="0" y1="-5" x2="0" y2="5" class="figure-line"></line><line x1="-5" y1="0" x2="5" y2="0" class="figure-line"></line></g><g class="figure-faded"><path d="M 170 20 L 170 -10" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(170, -10)" class="figure-path"></use><path d="M 110 60 L 110 36 A 6 6 0 0 1 116 30 L 155 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(155, 30)" class="figure-path"></use><path d="M 230 60 L 230 36 A 6 6 0 0 0 224 30 L 185 30" class="figure-line"></path><use xlink:href="#arrow-left" transform="translate(185, 30)" class="figure-path"></use></g><g transform="translate(60, 180)"><rect width="100" height="30" class="figure-element figure-box figure-filmed-network figure-faded"></rect><text x="50" y="15" dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded">linear</text></g><g class="figure-faded"><path d="M 110 180 L 110 155" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(110, 155)" class="figure-path"></use></g><g transform="translate(60, 120)"><rect width="100" height="30" class="figure-element figure-box figure-filmed-network figure-faded"></rect><text x="50" y="15" dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded">normalization</text></g><g class="figure-faded"><path d="M 110 120 L 110 95" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(110, 95)" class="figure-path"></use></g><g transform="translate(60, 60)"><rect width="100" height="30" class="figure-element figure-box figure-filmed-network"></rect><text x="50" y="15" dy="0.4em" style="text-anchor: middle;" class="figure-text">FiLM</text></g><g transform="translate(180, 180)"><rect width="100" height="30" class="figure-element figure-box figure-filmed-network figure-faded"></rect><text x="50" y="15" dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded">linear</text></g><g class="figure-faded"><path d="M 230 180 L 230 155" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(230, 155)" class="figure-path"></use></g><g transform="translate(180, 120)"><rect width="100" height="30" class="figure-element figure-box figure-filmed-network figure-faded"></rect><text x="50" y="15" dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded">normalization</text></g><g class="figure-faded"><path d="M 230 120 L 230 95" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(230, 95)" class="figure-path"></use></g><g transform="translate(180, 60)"><rect width="100" height="30" class="figure-element figure-box figure-filmed-network"></rect><text x="50" y="15" dy="0.4em" style="text-anchor: middle;" class="figure-text">FiLM</text></g><text x="110" y="270" dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded"><tspan style="font-weight: bold;">h</tspan><tspan dy="5px" class="subscript">t-1</tspan></text><g class="figure-faded"><path d="M 110 260 L 110 215" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(110, 215)" class="figure-path"></use></g><text x="230" y="270" dy="0.4em" style="text-anchor: middle;" class="figure-text figure-text-faded"><tspan style="font-weight: bold;">x</tspan><tspan dy="5px" class="subscript">t</tspan></text><g class="figure-faded"><path d="M 230 260 L 230 215" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(230, 215)" class="figure-path"></use></g><g transform="translate(-60, 180)"><rect width="100" height="30" class="figure-element figure-box figure-film-generator"></rect><text x="50" y="15" dy="0.4em" style="text-anchor: middle;" class="figure-text">FiLM generator</text></g><path d="M -10 255 L -10 215" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(-10, 215)" class="figure-path"></use><path d="M -10 180 L -10 117 A 6 6 0 0 1 -4 111 L 84 111 A 6 6 0 0 0 90 105 L 90 95" class="figure-line"></path><path d="M -10 180 L -10 117 A 6 6 0 0 1 -4 111 L 204 111 A 6 6 0 0 0 210 105 L 210 95" class="figure-line"></path><use xlink:href="#arrow-up" transform="translate(90, 95)" class="figure-path"></use><use xlink:href="#arrow-up" transform="translate(210, 95)" class="figure-path"></use><g transform="translate(-10, 270)"><text x="0" y="0" dy="-0.25em" style="font-weight: bold; text-anchor: middle;" class="figure-text"><tspan> utterance </tspan><tspan x="0" dy="1.25em"> summarization </tspan></text></g></g></g></svg>
  </figure>
  <p class="content" content-name="speech-recognition" content-type="literature">
    The key difference here is that the conditioning signal does not come from
    an external source but rather from utterance
    summarization feature vectors extracted in each layer to adapt the model.
  </p>
  <button class="collapsible" content-name="domain-adaptation" content-type="literature">Domain adaptation and few-shot learning<span style="float: right;">+</span></button>
  <p class="content" content-name="domain-adaptation" content-type="literature">
    For domain adaptation, Li et al. <d-cite key="li2018adaptive"></d-cite>
    find it effective to update the per-channel batch normalization
    statistics (mean and variance) of a network trained on one domain with that
    network's statistics in a new, target domain. As discussed in the
    <em>Style transfer</em> subsection, this operation is akin to using the network as
    both the FiLM generator and the FiLM-ed network. Notably, this approach,
    along with Adaptive Instance Normalization, has the particular advantage of
    not requiring any extra trainable parameters.
  </p>
  <p class="content" content-name="domain-adaptation" content-type="literature">
    For few-shot learning, Oreshkin et al.
    <d-cite key="oreshkin2018tadam"></d-cite> explore the use of FiLM layers to
    provide more robustness to variations in the input distribution across
    few-shot learning episodes. The training set for a given episode is used to
    produce FiLM parameters which modulate the feature extractor used in a
    Prototypical Networks <d-cite key="snell2017prototypical"></d-cite>
    meta-training procedure.
  </p>

  <hr/>

  <h2>Related ideas</h2>
  <p>
    Aside from methods which make direct use of feature-wise transformations,
    the FiLM framework connects more broadly with the following methods and
    concepts.
  </p>
  <div style="width: 100%">
    <button class="expand-collapse-button" content-type="related">expand all</button>
  </div>
  <button class="collapsible" content-name="zero-shot" content-type="related">Zero-shot learning<span style="float: right;">+</span></button>
  <p class="content" content-name="zero-shot" content-type="related">
    The idea of learning a task representation shares a strong connection with
    zero-shot learning approaches.  In zero-shot learning, semantic task
    embeddings may be learned from external information and then leveraged to
    make predictions about classes without training examples. For instance, to
    generalize to unseen object categories for image classification, one may
    construct semantic task embeddings from text-only descriptions and exploit
    objects' text-based relationships to make predictions for unseen image
    categories. Frome et al. <d-cite key="frome2013devise"></d-cite>, Socher et
    al.  <d-cite key="socher2013zero"></d-cite>, and Norouzi et al.
    <d-cite key="norouzi2014zero"></d-cite> are a few notable exemplars
    of this idea.
  </p>
  <button class="collapsible" content-name="hypernetworks" content-type="related">HyperNetworks<span style="float: right;">+</span></button>
  <p class="content" content-name="hypernetworks" content-type="related">
    The notion of a secondary network predicting the parameters of a primary
    network is also well exemplified by HyperNetworks <d-cite
    key="ha2016hypernetworks"></d-cite>, which predict weights for entire layers
    (e.g., a recurrent neural network layer).  From this perspective, the FiLM
    generator is a specialized HyperNetwork that predicts the FiLM parameters of
    the FiLM-ed network. The main distinction between the two resides in the
    number and specificity of predicted parameters: FiLM requires predicting far
    fewer parameters than Hypernetworks, but also has less modulation potential.
    The ideal trade-off between a conditioning mechanism's capacity,
    regularization, and computational complexity is still an ongoing area of
    investigation, and many proposed approaches lie on the spectrum between FiLM
    and HyperNetworks (see <a href="#bibliographic-notes">Bibliographic Notes</a>).
  </p>
  <button class="collapsible" content-name="attention" content-type="related">Attention<span style="float: right;">+</span></button>
  <p class="content" content-name="attention" content-type="related">
    Some parallels can be drawn between attention and FiLM, but the two operate
    in different ways which are important to disambiguate.
  </p>
  <figure class="content l-body-outset" content-name="attention" content-type="related" id="film-vs-attention-diagram">
    <svg viewBox="0 0 888 470" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><rect id="convolutional-patch-positive" width="20" height="20" rx="6" ry="6" opacity="0.8" style="fill: #80DEEA;"></rect><rect id="convolutional-patch-negative" width="20" height="20" rx="6" ry="6" opacity="0.8" style="fill: #FFAB91;"></rect><path id="convolutional-feature" d="M 0 0 l 30 0 l 0 30 l -30 0 Z"></path></defs><g transform="translate(-5, 0)"><g transform="translate(270,10)"><text x="0" y="0" class="figure-text"><tspan><tspan style="font-weight: bold;">Attention</tspan> computes a </tspan><tspan x="0" dy="1.5em"> probability distribution </tspan><tspan x="0" dy="1.5em"> over <tspan style="font-weight: bold;">locations</tspan>. </tspan></text></g><g transform="translate(500,10)"><text x="0" y="0" class="figure-text"><tspan><tspan style="font-weight: bold;">Attention pools</tspan></tspan><tspan x="0" dy="1.5em"> over locations. </tspan></text></g><g transform="translate(757,10)"><text x="0" y="0" class="figure-text"><tspan><tspan style="font-weight: bold;">Attention</tspan> summarizes </tspan><tspan x="0" dy="1.5em"> the input into a vector. </tspan></text></g><g transform="translate(270,280)"><text x="0" y="0" class="figure-text"><tspan><tspan style="font-weight: bold;">FiLM</tspan> computes a scaling </tspan><tspan x="0" dy="1.5em"> vector applied to the </tspan><tspan x="0" dy="1.5em"><tspan style="font-weight: bold;">feature</tspan> axis. </tspan></text></g><g transform="translate(757,280)"><text x="0" y="0" class="figure-text"><tspan><tspan style="font-weight: bold;">FiLM</tspan> conserves </tspan><tspan x="0" dy="1.5em"> input dimensions. </tspan></text></g><g id="cnn-figure-attention" transform="translate(10,130)"><g id="input-conv-att" transform="translate(0,0)"><g transform="translate(45,0)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g><g transform="translate(45,-20)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g><g transform="translate(45,-40)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g></g><g transform="translate(200,0)"><circle r="15" class="figure-element" style="fill:#e8e8e8;" cy="0" cx="0"></circle><circle r="2" cy="0" cx="0" class="figure-path"></circle></g><text class="figure-text" style="font-size: 18px; font-family: serif;" y="-30" x="325"></text><g id="alpha-conv-att" transform="translate(245,0)"><g transform="translate(45,-20)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g></g><g id="out-conv-att" transform="translate(450,0)"><g transform="translate(45, 0)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g><g transform="translate(45,-20)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g><g transform="translate(45,-40)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g></g><g transform="translate(600,20)"><text x="60" y="-40" dy="-0.4em" class="figure-text" style="font-size:20px; font-family:serif; text-anchor: middle;"></text><path d="M 0 0 L 120 0" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(120,0)" class="figure-path"></use><path d="M 0 -20 L 120 -20" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(120,-20)" class="figure-path"></use><path d="M 0 -40 L 120 -40" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(120,-40)" class="figure-path"></use></g><path d="M 380 0 430 0" class="figure-line"></path><use transform="translate(430 0)" class="figure-path" xlink:href="#arrow-right"></use><g transform="translate(810,10)" id="out-feat-att"><g transform="matrix(1,0,-0.5,0.5,0,0)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5,5)" class="convolutional-patch"></use></g><g transform="matrix(1,0,-0.5,0.5,0,-20)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5,5)" class="convolutional-patch"></use></g><g transform="matrix(1,0,-0.5,0.5,0,-40)" class="feature"><use xlink:href="#convolutional-feature" class="figure-element"></use><use xlink:href="#convolutional-patch-negative" transform="translate(5,5)" class="convolutional-patch"></use></g></g></g><g id="cnn-figure-film" transform="translate(10,420)"><g id="input-conv-film" transform="translate(0,0)"><g transform="translate(45,0)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g><g transform="translate(45,-20)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g><g transform="translate(45,-40)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g></g><g transform="translate(200,0)"><circle r="15" class="figure-element" style="fill:#e8e8e8" cy="0" cx="0"></circle><circle r="2" cy="0" cx="0" class="figure-path"></circle></g><g id="gamma-conv-film" transform="translate(290,10)"><g transform="translate(0, 0)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g><g transform="translate(0,-20)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g><g transform="translate(0,-40)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g></g><path d="M 380 0 430 0" class="figure-line"></path><use transform="translate(430 0)" class="figure-path" xlink:href="#arrow-right"></use><text class="figure-text" x="480" y="0" style="text-anchor: middle; font-size: 18px;">...</text><text class="figure-text" x="480" y="0" dy="-2em" style="text-anchor: middle; opacity: 0.3;">( omitted for clarity)</text><text class="figure-text" x="300" y="-45" style="font-family: serif; font-size: 18px;"></text><path d="M 530 0 720 0" class="figure-line"></path><use class="figure-path" transform="translate(720,0)" xlink:href="#arrow-right"></use><g id="out-conv-film" transform="translate(735,0)"><g transform="translate(45,0)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g><g transform="translate(45,-20)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g><g transform="translate(45,-40)"><g class="feature" transform="matrix(1,0,-0.5,0.5,0,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,60,0)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,15,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,45,15)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,-30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,0,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g><g class="feature" transform="matrix(1,0,-0.5,0.5,30,30)"><use class="figure-element" xlink:href="#convolutional-feature"></use><use class="convolutional-patch" transform="translate(5,5)" xlink:href="#convolutional-patch-negative"></use></g></g></g></g></g></svg>
  </figure>
  <p class="content" content-name="attention" content-type="related">
    This difference stems from distinct intuitions underlying attention and
    FiLM: the former assumes that specific spatial locations or time steps
    contain the most useful information, whereas the latter assumes that
    specific features or feature maps contain the most useful information.
  </p>
  <button class="collapsible" content-name="bilinear" content-type="related">Bilinear transformations<span style="float: right;">+</span></button>
  <p class="content" content-name="bilinear" content-type="related">
    With a little bit of stretching, FiLM can be seen as a special case of a
    bilinear transformation
    <d-cite key="tenenbaum2000separating"></d-cite> with low-rank weight
    matrices. A bilinear transformation defines the relationship between two
    inputs <d-math>\mathbf{x}</d-math> and <d-math>\mathbf{z}</d-math> and the
    <d-math>k^{th}</d-math> output feature <d-math>y_k</d-math> as

    <d-math block>
      y_k = \mathbf{x}^T W_k \mathbf{z}.
    </d-math>

    Note that for each output feature <d-math>y_k</d-math> we have a separate
    matrix <d-math>W_k</d-math>, so the full set of weights forms a
    multi-dimensional array.
  </p>
  <figure class="content l-body-outset" content-name="bilinear" content-type="related">
    <svg viewBox="0 0 888 340" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-up" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z"></path><path id="big-row-left" d="M 0 6 a 6 6 0 0 1 6 -6 l 34 0 l 0 40 l -34 0 a 6 6 0 0 1 -6 -6 Z"></path><path id="big-row-middle" d="M 0 0 l 40 0 l 0 40 l -40 0 Z"></path><path id="big-row-right" d="M 0 0 l 34 0 a 6 6 0 0 1 6 6 l 0 28 a 6 6 0 0 1 -6 6 l -34 0 Z"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path><path id="matrix-top-left" d="M 0 6 a 6 6 0 0 1 6 -6 l 14 0 l 0 20 l -20 0 Z"></path><path id="matrix-top-right" d="M 0 0 l 14 0 a 6 6 0 0 1 6 6 l 0 14l -20 0 Z"></path><path id="matrix-bottom-left" d="M 0 0 l 20 0 l 0 20 l -14 0 a 6 6 0 0 1 -6 -6 Z"></path><path id="matrix-bottom-right" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -14 0 Z"></path><path id="matrix-center" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="curly-brace-horizontal" d="M 0 0 C 0 -16 42.5 0 42.5 -16 C 42.5 0 85 -16 85 0"></path><path id="bigger-curly-brace-horizontal" d="M 0 0 C 0 -16 72.5 0 72.5 -16 C 72.5 0 145 -16 145 0"></path></defs><text x="10" y="10" dy="1em" class="figure-text"><tspan> Each element y<tspan dy="4px" class="subscript">k</tspan></tspan><tspan dy="-4px"> of the output vector <tspan style="font-weight: bold;">y</tspan> is the </tspan><tspan x="10" dy="1.5em"> result of a distinct vector-matrix-vector product. </tspan><tspan x="10" dy="1.5em"> This enables multiplicative interactions between </tspan><tspan x="10" dy="1.5em"> any pair of elements of <tspan style="font-weight: bold;">x</tspan> and <tspan style="font-weight: bold;">z</tspan>. </tspan></text><g transform="translate(300, 10)"><g transform="translate(222, 0)"><use xlink:href="#big-row-left" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#big-row-middle" transform="translate(40, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#big-row-right" transform="translate(80, 0)" class="figure-filmed-network figure-element"></use><text x="-15" y="20" dy="0.4em" dy="0.4em" style="font-weight: bold;" class="figure-text">y</text><path class="figure-line" d="M -179.5 74 C -179.5 54 30 95 20 45"></path><use xlink:href="#arrow-up" transform="translate(20, 45)" class="figure-path"></use><path class="figure-line" d="M 25.5 74 C 25.5 64 60 75 60 45"></path><use xlink:href="#arrow-up" transform="translate(60, 45)" class="figure-path"></use><path class="figure-line" d="M 230.5 74 C 230.5 64 90 85 100 45"></path><use xlink:href="#arrow-up" transform="translate(100, 45)" class="figure-path"></use></g><g transform="translate(0, 100)"><g transform="translate(0, 0)"><use xlink:href="#row-left" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-middle" transform="translate(20, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-right" transform="translate(40, 0)" class="figure-filmed-network figure-element"></use><text x="30" y="30" dy="0.4em" style="text-anchor: middle; font-weight: bold" class="figure-text">x</text></g><g transform="translate(65, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><text x="25" y="30" dy="0.4em" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">1</tspan><tspan dy="-4px" style="font-weight: bold;"> z</tspan></text></g><use xlink:href="#curly-brace-horizontal" transform="translate(0, -5)" class="figure-line"></use><g transform="translate(205, 0)"><use xlink:href="#row-left" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-middle" transform="translate(20, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-right" transform="translate(40, 0)" class="figure-filmed-network figure-element"></use><text x="30" y="30" dy="0.4em" style="text-anchor: middle; font-weight: bold" class="figure-text">x</text></g><g transform="translate(270, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><text x="25" y="30" dy="0.4em" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">2</tspan><tspan dy="-4px" style="font-weight: bold;"> z</tspan></text></g><use xlink:href="#curly-brace-horizontal" transform="translate(205, -5)" class="figure-line"></use><g transform="translate(410, 0)"><use xlink:href="#row-left" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-middle" transform="translate(20, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-right" transform="translate(40, 0)" class="figure-filmed-network figure-element"></use><text x="30" y="30" dy="0.4em" style="text-anchor: middle; font-weight: bold" class="figure-text">x</text></g><use xlink:href="#curly-brace-horizontal" transform="translate(410, -5)" class="figure-line"></use><g transform="translate(475, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><text x="25" y="30" dy="0.4em" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">3</tspan><tspan dy="-4px" style="font-weight: bold;"> z</tspan></text></g></g><g transform="translate(2.5, 190)"><g transform="translate(0, 0)"><use xlink:href="#matrix-top-left" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-top-right" transform="translate(100, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(100, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-bottom-left" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-bottom-right" transform="translate(100, 40)" class="figure-film-generator figure-element"></use><text x="60" y="75" style="text-anchor: middle;" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">1</tspan></text></g><g transform="translate(125, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 80)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 100)" class="figure-film-generator figure-element"></use><text x="10" y="135" style="text-anchor: middle; font-weight: bold;" class="figure-text">z</text></g><use xlink:href="#bigger-curly-brace-horizontal" transform="translate(0, -5)" class="figure-line"></use><g transform="translate(205, 0)"><use xlink:href="#matrix-top-left" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-top-right" transform="translate(100, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(100, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-bottom-left" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-bottom-right" transform="translate(100, 40)" class="figure-film-generator figure-element"></use><text x="60" y="75" style="text-anchor: middle;" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">2</tspan></text></g><g transform="translate(330, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 80)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 100)" class="figure-film-generator figure-element"></use><text x="10" y="135" style="text-anchor: middle; font-weight: bold;" class="figure-text">z</text></g><use xlink:href="#bigger-curly-brace-horizontal" transform="translate(205, -5)" class="figure-line"></use><g transform="translate(410, 0)"><use xlink:href="#matrix-top-left" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-top-right" transform="translate(100, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(100, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-bottom-left" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-bottom-right" transform="translate(100, 40)" class="figure-film-generator figure-element"></use><text x="60" y="75" style="text-anchor: middle;" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">3</tspan></text></g><g transform="translate(535, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 80)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 100)" class="figure-film-generator figure-element"></use><text x="10" y="135" style="text-anchor: middle; font-weight: bold;" class="figure-text">z</text></g><use xlink:href="#bigger-curly-brace-horizontal" transform="translate(410, -5)" class="figure-line"></use></g></g></svg>
  </figure>
  <p class="content" content-name="bilinear" content-type="related">
    If we view <d-math>\mathbf{z}</d-math> as the concatenation of the scaling
    and shifting vectors <d-math>\gamma</d-math> and <d-math>\beta</d-math> and
    if we augment the input <d-math>\mathbf{x}</d-math> with a 1-valued feature,
    <d-footnote>
      As is commonly done to turn a linear transformation into an affine
      transformation.
    </d-footnote>
    we can represent FiLM using a bilinear transformation by zeroing out the
    appropriate weight matrix entries:
  </p>
  <figure class="content l-body-outset" content-name="bilinear" content-type="related">
    <svg viewBox="0 0 888 380" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-up" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z"></path><path id="big-row-left" d="M 0 6 a 6 6 0 0 1 6 -6 l 34 0 l 0 40 l -34 0 a 6 6 0 0 1 -6 -6 Z"></path><path id="big-row-middle" d="M 0 0 l 40 0 l 0 40 l -40 0 Z"></path><path id="big-row-right" d="M 0 0 l 34 0 a 6 6 0 0 1 6 6 l 0 28 a 6 6 0 0 1 -6 6 l -34 0 Z"></path><path id="singleton" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 8 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path><path id="column-top" d="M 0 6 a 6 6 0 0 1 6 -6 l 8 0 a 6 6 0 0 1 6 6 l 0 14 l -20 0 Z"></path><path id="column-middle" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="column-bottom" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -8 0 a 6 6 0 0 1 -6 -6 Z"></path><path id="matrix-top-left" d="M 0 6 a 6 6 0 0 1 6 -6 l 14 0 l 0 20 l -20 0 Z"></path><path id="matrix-top-right" d="M 0 0 l 14 0 a 6 6 0 0 1 6 6 l 0 14l -20 0 Z"></path><path id="matrix-bottom-left" d="M 0 0 l 20 0 l 0 20 l -14 0 a 6 6 0 0 1 -6 -6 Z"></path><path id="matrix-bottom-right" d="M 0 0 l 20 0 l 0 14 a 6 6 0 0 1 -6 6 l -14 0 Z"></path><path id="matrix-center" d="M 0 0 l 20 0 l 0 20 l -20 0 Z"></path><path id="big-curly-brace-horizontal" d="M 0 0 C 0 -16 52.5 0 52.5 -16 C 52.5 0 105 -16 105 0"></path><path id="bigger-curly-brace-horizontal" d="M 0 0 C 0 -16 72.5 0 72.5 -16 C 72.5 0 145 -16 145 0"></path><path id="curly-brace-vertical" d="M 0 0 C 12 0 0 30 12 30 C 0 30 12 60 0 60"></path></defs><text x="10" y="10" dy="1em" class="figure-text"><tspan> FiLM computes elements of the output </tspan><tspan x="10" dy="1.5em"> vector as y<tspan dy="4px" class="subscript">k</tspan></tspan><tspan dy="-4px"> = <tspan style="font-family: serif;"></tspan><tspan dy="4px" class="subscript">k</tspan></tspan><tspan dy="-4px"> x<tspan dy="4px" class="subscript">k</tspan></tspan><tspan dy="-4px"> + <tspan style="font-family: serif;"></tspan><tspan dy="4px" class="subscript">k</tspan>. </tspan></text><text x="10" y="100" dy="1em" class="figure-text"><tspan> This can be expressed as a dot product </tspan><tspan x="10" dy="1.5em"> between a 1-augmented <tspan style="font-weight: bold;">x</tspan> and a sparse </tspan><tspan x="10" dy="1.5em"> vector containing <tspan style="font-family: serif;"></tspan><tspan dy="4px" class="subscript">k</tspan></tspan><tspan dy="-4px"> and <tspan style="font-family: serif;"></tspan><tspan dy="4px" class="subscript">k</tspan>. </tspan><tspan dy="-4px"> (Shaded </tspan><tspan x="10" dy="1.5em"> cells have a zero value.) </tspan></text><text x="10" y="210" dy="1em" class="figure-text"><tspan> The sparse vector is given by multiplying </tspan><tspan x="10" dy="1.5em"> a low-rank weight matrix with the </tspan><tspan x="10" dy="1.5em"> concatenation of <tspan style="font-family: serif;"></tspan> and <tspan style="font-family: serif;"></tspan>. (Shaded cells </tspan><tspan x="10" dy="1.5em"> again have a zero value.) </tspan></text><g transform="translate(280, 10)"><g transform="translate(222, 0)"><use xlink:href="#big-row-left" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#big-row-middle" transform="translate(40, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#big-row-right" transform="translate(80, 0)" class="figure-filmed-network figure-element"></use><text x="-15" y="20" dy="0.4em" dy="0.4em" style="font-weight: bold;" class="figure-text">y</text><path class="figure-line" d="M -169.5 74 C -169.5 64 30 95 20 45"></path><use xlink:href="#arrow-up" transform="translate(20, 45)" class="figure-path"></use><path class="figure-line" d="M 35.5 74 C 35.5 64 60 75 60 45"></path><use xlink:href="#arrow-up" transform="translate(60, 45)" class="figure-path"></use><path class="figure-line" d="M 240.5 74 C 240.5 64 90 85 100 45"></path><use xlink:href="#arrow-up" transform="translate(100, 45)" class="figure-path"></use></g><g transform="translate(0, 100)"><g transform="translate(0, 0)"><use xlink:href="#row-left" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-middle" transform="translate(20, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-right" transform="translate(40, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#singleton" transform="translate(60, 0)" class="figure-filmed-network figure-element"></use><text x="70" y="10" dy="0.4em" style="text-anchor: middle;" class="figure-text">1</text><text x="30" y="30" dy="0.4em" style="text-anchor: middle; font-weight: bold" class="figure-text">x</text></g><g transform="translate(85, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-film-generator figure-element"></use><text x="25" y="40" dy="0.4em" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">1</tspan><tspan dy="-4px" style="font-weight: bold;"> z</tspan></text></g><use xlink:href="#big-curly-brace-horizontal" transform="translate(0, -5)" class="figure-line"></use><g transform="translate(205, 0)"><use xlink:href="#row-left" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-middle" transform="translate(20, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-right" transform="translate(40, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#singleton" transform="translate(60, 0)" class="figure-filmed-network figure-element"></use><text x="70" y="10" dy="0.4em" style="text-anchor: middle;" class="figure-text">1</text><text x="30" y="30" dy="0.4em" style="text-anchor: middle; font-weight: bold" class="figure-text">x</text></g><g transform="translate(290, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-film-generator figure-element"></use><text x="25" y="40" dy="0.4em" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">2</tspan><tspan dy="-4px" style="font-weight: bold;"> z</tspan></text></g><use xlink:href="#big-curly-brace-horizontal" transform="translate(205, -5)" class="figure-line"></use><g transform="translate(410, 0)"><use xlink:href="#row-left" transform="translate(0, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-middle" transform="translate(20, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#row-right" transform="translate(40, 0)" class="figure-filmed-network figure-element"></use><use xlink:href="#singleton" transform="translate(60, 0)" class="figure-filmed-network figure-element"></use><text x="70" y="10" dy="0.4em" style="text-anchor: middle;" class="figure-text">1</text><text x="30" y="30" dy="0.4em" style="text-anchor: middle; font-weight: bold" class="figure-text">x</text></g><use xlink:href="#big-curly-brace-horizontal" transform="translate(410, -5)" class="figure-line"></use><g transform="translate(495, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 60)" class="figure-film-generator figure-element"></use><text x="25" y="40" dy="0.4em" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">3</tspan><tspan dy="-4px" style="font-weight: bold;"> z</tspan></text></g></g><g transform="translate(22.5, 210)"><g transform="translate(0, 0)"><use xlink:href="#matrix-top-left" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-top-right" transform="translate(100, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(100, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(100, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-bottom-left" transform="translate(0, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-bottom-right" transform="translate(100, 60)" class="figure-film-generator-shaded figure-element"></use><text x="60" y="95" style="text-anchor: middle;" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">1</tspan></text><text x="10" y="10" dy="0.4em" style="text-anchor: middle;" class="figure-text">1</text><text x="70" y="70" dy="0.4em" style="text-anchor: middle;" class="figure-text">1</text></g><g transform="translate(125, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 80)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 100)" class="figure-film-generator figure-element"></use><text x="10" y="135" style="text-anchor: middle; font-weight: bold;" class="figure-text">z</text></g><use xlink:href="#curly-brace-vertical" transform="translate(150, 0)" class="figure-line"></use><text x="170" y="30" dy="0.3em" style="font-family: serif;" class="figure-text"></text><text x="170" y="90" dy="0.3em" style="font-family: serif;" class="figure-text"></text><use xlink:href="#curly-brace-vertical" transform="translate(150, 60)" class="figure-line"></use><use xlink:href="#bigger-curly-brace-horizontal" transform="translate(0, -5)" class="figure-line"></use><g transform="translate(205, 0)"><use xlink:href="#matrix-top-left" transform="translate(0, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-top-right" transform="translate(100, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(100, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(100, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-bottom-left" transform="translate(0, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-bottom-right" transform="translate(100, 60)" class="figure-film-generator-shaded figure-element"></use><text x="60" y="95" style="text-anchor: middle;" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">2</tspan></text><text x="30" y="30" dy="0.4em" style="text-anchor: middle;" class="figure-text">1</text><text x="90" y="70" dy="0.4em" style="text-anchor: middle;" class="figure-text">1</text></g><g transform="translate(330, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 80)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 100)" class="figure-film-generator figure-element"></use><text x="10" y="135" style="text-anchor: middle; font-weight: bold;" class="figure-text">z</text></g><use xlink:href="#curly-brace-vertical" transform="translate(355, 0)" class="figure-line"></use><text x="375" y="30" dy="0.3em" style="font-family: serif;" class="figure-text"></text><text x="375" y="90" dy="0.3em" style="font-family: serif;" class="figure-text"></text><use xlink:href="#curly-brace-vertical" transform="translate(355, 60)" class="figure-line"></use><use xlink:href="#bigger-curly-brace-horizontal" transform="translate(205, -5)" class="figure-line"></use><g transform="translate(410, 0)"><use xlink:href="#matrix-top-left" transform="translate(0, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-top-right" transform="translate(100, 0)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(100, 20)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(0, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(100, 40)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-bottom-left" transform="translate(0, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(20, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(40, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(60, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-center" transform="translate(80, 60)" class="figure-film-generator-shaded figure-element"></use><use xlink:href="#matrix-bottom-right" transform="translate(100, 60)" class="figure-film-generator figure-element"></use><text x="60" y="95" style="text-anchor: middle;" class="figure-text"><tspan>W</tspan><tspan dy="4px" class="subscript">3</tspan></text><text x="50" y="50" dy="0.4em" style="text-anchor: middle;" class="figure-text">1</text><text x="110" y="70" dy="0.4em" style="text-anchor: middle;" class="figure-text">1</text></g><g transform="translate(535, 0)"><use xlink:href="#column-top" transform="translate(0, 0)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 20)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 40)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 60)" class="figure-film-generator figure-element"></use><use xlink:href="#column-middle" transform="translate(0, 80)" class="figure-film-generator figure-element"></use><use xlink:href="#column-bottom" transform="translate(0, 100)" class="figure-film-generator figure-element"></use><text x="10" y="135" style="text-anchor: middle; font-weight: bold;" class="figure-text">z</text></g><use xlink:href="#curly-brace-vertical" transform="translate(560, 0)" class="figure-line"></use><text x="580" y="30" dy="0.3em" style="font-family: serif;" class="figure-text"></text><text x="580" y="90" dy="0.3em" style="font-family: serif;" class="figure-text"></text><use xlink:href="#curly-brace-vertical" transform="translate(560, 60)" class="figure-line"></use><use xlink:href="#bigger-curly-brace-horizontal" transform="translate(410, -5)" class="figure-line"></use></g></svg>
  </figure>
  <p class="content" content-name="bilinear" content-type="related">
    For some applications of bilinear transformations,
    see the <a href="#bibliographic-notes">Bibliographic Notes</a>.
  </p>

  <hr/>

  <h2>Properties of the learned task representation</h2>
  <p>
    As hinted earlier, in adopting the FiLM perspective we implicitly introduce
    a notion of <em>task representation</em>: each task &mdash; be it a question
    about an image or a painting style to imitate &mdash; elicits a different
    set of FiLM parameters via the FiLM generator which can be understood as its
    representation in terms of how to modulate the FiLM-ed network. To help
    better understand the properties of this representation, let's focus on two
    FiLM-ed models used in fairly different problem settings:
  </p>
  <ul>
    <li>
      The visual reasoning model of Perez et al.
      <d-cite key="perez2017learning,perez2018film"></d-cite>, which uses FiLM
      to modulate a visual processing pipeline based off an input question.
      <figure class="l-body-outset">
        <svg viewBox="0 0 888 500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-left" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z" transform="rotate(180, 0, 0)"></path><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><g transform="translate(10, 10)" class="film-generator"><text x="0" y="30" dy="1em" class="figure-text"><tspan> The <tspan style="font-weight: bold;">linguistic pipeline</tspan></tspan><tspan x="0" dy="1.5em"> acts as the FiLM generator. </tspan></text><text x="0" y="300" dy="1em" class="figure-text"><tspan> FiLM layers in each residual </tspan><tspan x="0" dy="1.5em"> block modulate the <tspan style="font-weight: bold;">visual</tspan></tspan><tspan x="0" dy="1.5em"><tspan style="font-weight: bold;">pipeline</tspan>. </tspan></text><g transform="translate(140, 0)"><image x="48" y="300" width="96" height="96" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/clevr_input.jpg"></image><g class="figure-faded"><path d="M 144 348 L 175 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(175, 348)" class="figure-path"></use></g><g transform="translate(180, 288)" class="figure-faded"><rect width="50" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="25" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 25, 60)" class="figure-text">feature extractor</text></g><g class="figure-faded"><path d="M 230 348 L 420 348" class="figure-line"></path><path d="M 230 348 C 260 348 242.5 278 272.5 278" class="figure-line"></path><path d="M 362.5 278 C 392.5 278 380 348 420 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(420, 348)" class="figure-path"></use></g><g transform="translate(272.5, 218)"><g transform="translate(0, 0)" class="figure-faded"><rect width="50" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="25" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 25, 60)" class="figure-text">sub-network</text></g><g class="figure-faded"><path d="M 50 60 L 60 60" class="figure-line"></path></g><g transform="translate(60, 0)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="font-weight: bold; text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">FiLM layer</text></g></g><g transform="translate(425, 288)" class="figure-faded"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">ReLU</text></g><path d="M 242.5 410 L 242.5 420 L 465 420 L 465 410" style="stroke-width: 1px;" class="figure-line"></path><text x="242.5" y="420" dy="1.5em" class="figure-text"><tspan> Each <tspan style="font-weight: bold;">residual block</tspan> has a </tspan><tspan x="242.5" dy="1.5em"> FiLM layer added to it. </tspan></text><g class="figure-faded"><path d="M 455 348 L 645 348" class="figure-line"></path><path d="M 455 348 C 485 348 467.5 278 497.5 278" class="figure-line"></path><path d="M 587.5 278 C 617.5 278 605 348 645 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(645, 348)" class="figure-path"></use></g><g transform="translate(497.5, 218)"><g transform="translate(0, 0)" class="figure-faded"><rect width="50" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="25" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 25, 60)" class="figure-text">sub-network</text></g><g class="figure-faded"><path d="M 50 60 L 60 60" class="figure-line"></path></g><g transform="translate(60, 0)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="font-weight: bold; text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">FiLM layer</text></g></g><g transform="translate(650, 288)" class="figure-faded"><rect width="50" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="25" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 25, 60)" class="figure-text">...</text></g><g class="figure-faded"><path d="M 700 348 L 730 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(730, 348)" class="figure-path"></use></g><g transform="translate(180, 100)"><rect width="520" height="40" class="figure-film-generator figure-element figure-box"></rect><text x="260" y="20" dy="0.4em" style="font-weight: bold; text-anchor: middle;" class="figure-text">linear</text></g><text x="180" y="150" dy="1em" class="figure-text">FiLM parameters</text><g class="figure-faded"><path d="M 700 60 L 724 60 a 6 6 0 0 1 6 6 L 730 114 a 6 6 0 0 1 -6 6 L 705 120" class="figure-line"></path><use xlink:href="#arrow-left" transform="translate(705, 120)" class="figure-path"></use><path d="M 675 140 L 675 283" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(675, 283)" class="figure-path"></use></g><path d="M 347.5 140 L 347.5 213" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(347.5, 213)" class="figure-path"></use><path d="M 572.5 140 L 572.5 213" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(572.5, 213)" class="figure-path"></use><g transform="translate(180, 30)"><g transform="translate(0, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">Are</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 30 30 L 76.66 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(76.66, 30)" class="figure-path"></use></g><g transform="translate(81.66, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">there</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 111.66 30 L 158.34 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(158.34, 30)" class="figure-path"></use></g><g transform="translate(163.34, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">more</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 193.34 30 L 240 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(240, 30)" class="figure-path"></use></g><g transform="translate(245, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">cubes</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 275 30 L 321.66 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(321.66, 30)" class="figure-path"></use></g><g transform="translate(326.66, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">than</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 356.66 30 L 403.34 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(403.34, 30)" class="figure-path"></use></g><g transform="translate(408.34, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">yellow</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g><g class="figure-faded"><path d="M 438.34 30 L 485 30" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(485, 30)" class="figure-path"></use></g><g transform="translate(490, 0)"><text x="15" y="-30" style="text-anchor: middle;" class="figure-text">things</text><g class="figure-faded"><path d="M 15 -25 L 15 -5" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(15, -5)" class="figure-path"></use></g><g class="figure-faded"><rect width="30" height="60" class="figure-film-generator figure-element figure-box"></rect><text x="15" y="30" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 30)" class="figure-text">GRU</text></g></g></g></g></g></svg>
      </figure>
    </li>
    <li>
      The artistic style transfer model of Ghiasi et al.
      <d-cite key="ghiasi2017exploring"></d-cite>, which uses FiLM to modulate a
      feed-forward style transfer network based off an input style image.
      <figure class="l-body-outset">
        <svg viewBox="0 0 888 420" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path><path id="arrow-down" d="M 0 0 C 1 2.779 2.445 5.376 4.28 7.69 L 0 6.14 L -4.28 7.69 C -2.444 5.376 -1 2.770 0 0 Z" transform="rotate(180, 0, 0)"></path></defs><g transform="translate(10, 10)"><text x="0" y="0" dy="1em" class="figure-text"><tspan> The <tspan style="font-weight: bold;">FiLM generator</tspan></tspan><tspan x="0" dy="1.5em"> predicts parameters </tspan><tspan x="0" dy="1.5em"> describing the target style. </tspan></text><text x="0" y="250" dy="1em" class="figure-text"><tspan> The <tspan style="font-weight: bold;">style transfer network</tspan></tspan><tspan x="0" dy="1.5em"> is conditioned by making </tspan><tspan x="0" dy="1.5em"> the instance normalization </tspan><tspan x="0" dy="1.5em"> parameters style-dependent. </tspan></text><g transform="translate(-15, 0)"><image x="200" y="0" width="96" height="96" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/cassis_cap_lombard_opus_196.jpg"></image><g transform="translate(340, 0)"><rect width="420" height="96" class="figure-film-generator figure-element figure-box"></rect><text x="210" y="48" dy="0.4em" style="font-weight: bold; text-anchor: middle;" class="figure-text">FiLM generator</text></g><g class="figure-faded"><path d="M 296 298 L 335 298" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(335, 298)" class="figure-path"></use><path d="M 760 298 L 789 298" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(789, 298)" class="figure-path"></use><path d="M 730 96 L 730 233" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(730, 233)" class="figure-path"></use></g><path d="M 296 48 L 335 48" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(335, 48)" class="figure-path"></use><path d="M 485 96 L 485 233" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(485, 233)" class="figure-path"></use><path d="M 665 96 L 665 233" class="figure-line"></path><use xlink:href="#arrow-down" transform="translate(665, 233)" class="figure-path"></use><text x="340" y="106" dy="1em" class="figure-text">FiLM parameters</text><image x="200" y="250" width="96" height="96" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/tuebingen_neckarfront.jpg"></image><g transform="translate(240, -50)"><g transform="translate(100, 288)"><rect width="60" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="30" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 30, 60)" class="figure-text figure-text-faded">sub-network</text></g><g class="figure-faded"><path d="M 160 348 L 175 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(175, 348)" class="figure-path"></use></g><g transform="translate(180, 288)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="15" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text figure-text-faded">normalization</text></g><g class="figure-faded"><path d="M 210 348 L 225 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(225, 348)" class="figure-path"></use></g><g transform="translate(230, 288)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="font-weight: bold; text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">FiLM layer</text></g><g class="figure-faded"><path d="M 260 348 L 275 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(275, 348)" class="figure-path"></use></g><g transform="translate(280, 288)"><rect width="60" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="30" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 30, 60)" class="figure-text figure-text-faded">sub-network</text></g><g class="figure-faded"><path d="M 340 348 L 355 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(355, 348)" class="figure-path"></use></g><g transform="translate(360, 288)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="15" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text figure-text-faded">normalization</text></g><g class="figure-faded"><path d="M 390 348 L 405 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(405, 348)" class="figure-path"></use></g><g transform="translate(410, 288)"><rect width="30" height="120" class="figure-filmed-network figure-element figure-box"></rect><text x="15" y="60" dy="0.4em" style="font-weight: bold; text-anchor: middle;" transform="rotate(-90, 15, 60)" class="figure-text">FiLM layer</text></g><g class="figure-faded"><path d="M 440 348 L 455 348" class="figure-line"></path><use xlink:href="#arrow-right" transform="translate(455, 348)" class="figure-path"></use></g><g transform="translate(460, 288)"><rect width="60" height="120" class="figure-filmed-network figure-element figure-box figure-faded"></rect><text x="30" y="60" dy="0.4em" style="text-anchor: middle;" transform="rotate(-90, 30, 60)" class="figure-text figure-text-faded">...</text></g><path d="M 175 410 L 175 420 L 265 420 L 265 410" style="stroke-width: 1px;" class="figure-line"></path><text x="175" y="420" dy="1.5em" class="figure-text"><tspan> conditional instance </tspan><tspan x="175" dy="1.5em"> normalization </tspan></text><path d="M 355 410 L 355 420 L 445 420 L 445 410" style="stroke-width: 1px;" class="figure-line"></path><text x="355" y="420" dy="1.5em" class="figure-text"><tspan> conditional instance </tspan><tspan x="355" dy="1.5em"> normalization </tspan></text><image x="554" y="300" width="96" height="96" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/tuebingen_neckarfront_cassis_cap_lombard_opus_196.jpg"></image></g></g></g></svg>
      </figure>
    </li>
  </ul>
  <p>
    As a starting point, can we discern any pattern in the FiLM parameters as a
    function of the task description? One way to visualize the FiLM parameter
    space is to plot <d-math>\gamma</d-math> against <d-math>\beta</d-math>,
    with each point corresponding to a specific task description and a specific
    feature map.  If we color-code each point according to the feature map it
    belongs to we observe the following:
  </p>
  <figure class="l-body" id="gamma-beta-diagram">
    <svg viewBox="0 0 704 480" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><text x="0" y="0" dy="1em" class="figure-text"> FiLM parameters for <tspan style="font-weight: bold;">256 tasks</tspan> and for <tspan style="font-weight: bold;">16 feature maps</tspan>, chosen randomly. </text><path d="M0,25l888,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="0" y="60" dy="1em" style="font-weight: bold;" class="figure-text"> Visual reasoning model </text><path d="M0,85l300,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="387" y="60" dy="1em" style="font-weight: bold;" class="figure-text"> Style transfer model </text><path d="M390,85l314,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><g id="clevr-plot"><rect x="0" y="110" width="300" height="300" style="fill: none;"></rect><path id="x-axis" d="M 0 0 L 0 0" class="figure-path"></path><text id="x-axis-label" x="0" y="0" dy="0.4em" style="font-family: serif;" class="figure-text"></text><path d="M 0 0 L 0 0" id="y-axis" class="figure-path"></path><text id="y-axis-label" x="0" y="0" dy="1em" style="font-family: serif;" class="figure-text"></text></g><text x="0" y="434" dy="1em" class="figure-text"> Feature map </text><g transform="translate(6, 465)" id="clevr-legend"></g><image x="290" y="451.5" height="27" width="27" xlink:href="images/pointer.svg"></image><g id="style-transfer-plot"><rect x="387" y="110" width="300" height="300" style="fill: none;"></rect><path id="x-axis" d="M 0 0 L 0 0" class="figure-path"></path><text id="x-axis-label" x="0" y="0" dy="0.4em" style="font-family: serif;" class="figure-text"></text><path d="M 0 0 L 0 0" id="y-axis" class="figure-path"></path><text id="y-axis-label" x="0" y="0" dy="1em" style="font-family: serif;" class="figure-text"></text></g><text x="387" y="434" dy="1em" class="figure-text"> Feature map </text><g transform="translate(393, 465)" id="style-transfer-legend"></g><image x="677" y="451.5" height="27" width="27" xlink:href="images/pointer.svg"></image></svg>
  </figure>
  <p>
    The plots above allow us to make several interesting observations.  First,
    FiLM parameters cluster by feature map in parameter space, and the cluster
    locations are not uniform across feature maps. The orientation of these
    clusters is also not uniform across feature maps: the main axis of variation
    can be <d-math>\gamma</d-math>-aligned, <d-math>\beta</d-math>-aligned, or
    diagonal at varying angles. These findings suggest that the affine
    transformation in FiLM layers is not modulated in a single, consistent way,
    i.e., using <d-math>\gamma</d-math> only, <d-math>\beta</d-math> only, or
    <d-math>\gamma</d-math> and <d-math>\beta</d-math> together in some specific
    way. Maybe this is due to the affine transformation being overspecified, or
    maybe this shows that FiLM layers can be used to perform modulation
    operations in several distinct ways.
  </p>
  <p>
    Nevertheless, the fact that these parameter clusters are often somewhat
    "dense" may help explain why the style transfer model of Ghiasi et al.
    <d-cite key="ghiasi2017exploring"></d-cite> is able to perform style
    interpolations: any convex combination of FiLM parameters is likely to
    correspond to a meaningful parametrization of the FiLM-ed network.
  </p>
  <figure class="l-body-outset" id="style-interpolation-diagram">
    <svg viewBox="0 0 888 380" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="interface"><g id="style-1-select"><text x="0" y="0" dy="1em" class="figure-text"><tspan style="font-weight: normal;">Style 1</tspan></text><line x1="0" y1="1.5em" x2="75" y2="1.5em" class="figure-line figure-faded"></line><g transform="translate(0, 40)"><image x="0" y="0" width="75" height="75" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/style-1-1.jpg"></image><image x="0" y="90" width="75" height="75" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/style-1-2.jpg"></image></g></g><g id="style-2-select" transform="translate(810, 0)"><text x="0" y="0" dy="1em" class="figure-text"><tspan style="font-weight: normal;">Style 2</tspan></text><line x1="0" y1="1.5em" x2="75" y2="1.5em" class="figure-line figure-faded"></line><g transform="translate(0, 40)"> w <image x="0" y="0" width="75" height="75" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/style-2-1.jpg"></image><image x="0" y="90" width="75" height="75" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/style-2-2.jpg"></image></g></g><g id="interpolation" transform="translate(90, 0)"><text x="0" y="0" dy="1em" class="figure-text"><tspan style="font-weight: bold;">Interpolation</tspan></text><line x1="0" y1="1.5em" x2="705" y2="1.5em" class="figure-line"></line><g transform="translate(0, 40)"><image x="0" y="0" width="165" height="165" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/stylized-1-1.jpg"></image><image x="180" y="0" width="165" height="165" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/stylized-1-2.jpg"></image><image x="360" y="0" width="165" height="165" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/stylized-1-3.jpg"></image><image x="540" y="0" width="165" height="165" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/stylized-1-4.jpg"></image></g></g><g id="content-select" transform="translate(0, 220)"><text x="0" y="0" dy="1em" class="figure-text"><tspan style="font-weight: normal;">Content Image</tspan></text><line x1="0" y1="1.5em" x2="980" y2="1.5em" class="figure-line figure-faded"></line><g transform="translate(0, 40)"><image x="0" y="0" width="80" height="80" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/content-1.jpg"></image><image x="100" y="0" width="80" height="80" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/content-2.jpg"></image><image x="200" y="0" width="80" height="80" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/content-3.jpg"></image><image x="300" y="0" width="80" height="80" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/content-4.jpg"></image></g></g></g></svg>
  </figure>
  <p>
    To some extent, the notion of interpolating between tasks using FiLM
    parameters can be applied even in the visual question-answering setting.
    Using the model trained in Perez et al. <d-cite key="perez2018film"></d-cite>,
    we interpolated between the model's FiLM parameters for two pairs of CLEVR
    questions. Here we visualize the input locations responsible for
    the globally max-pooled features fed to the visual pipeline's output classifier:
  </p>
  <figure class="l-body" id="question-interpolation-diagram">
    <svg viewBox="0 0 704 290" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><filter id="justAlphaandWhite"><feColorMatrix in="SourceAlpha" type="matrix" values="0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0"></feColorMatrix></filter><mask id="m-1"><image filter="url(#justAlphaandWhite)" width="250" height="166.67" xlink:href="images/question-interpolation-1-mask-1.png"></image></mask><mask id="m-2"><image filter="url(#justAlphaandWhite)" width="250" height="166.67" xlink:href="images/question-interpolation-2-mask-1.png"></image></mask></defs><path d="M352,10l0,260" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><g id="example-1" transform="translate(20, 0)"><image x="0" y="0" width="250" height="166.67" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/question-interpolation-1-input.png"></image><g mask="url(#m-1)"><rect x="0" y="0" width="250" height="166.67" style="fill: white; opacity: 0.9"></rect></g><g class="image-selector" transform="translate(3, 200)"><line x1="0" y1="0" x2="244" y2="0" class="figure-line"></line></g><text x="0" y="240" class="figure-text"><tspan> What shape is </tspan><tspan x="0" dy="1.5em"> the red thing left </tspan><tspan x="0" dy="1.5em"> of the sphere? </tspan></text><text x="170" y="240" class="figure-text"><tspan> What shape is </tspan><tspan x="170" dy="1.5em"> the red thing right </tspan><tspan x="170" dy="1.5em"> of the sphere? </tspan></text></g><g id="example-2" transform="translate(434, 0)"><image x="0" y="0" width="250" height="166.67" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/question-interpolation-2-input.png"></image><g mask="url(#m-2)"><rect x="0" y="0" width="250" height="166.67" style="fill: white; opacity: 0.9"></rect></g><g class="image-selector" transform="translate(3, 200)"><line x1="0" y1="0" x2="244" y2="0" class="figure-line"></line></g><text x="0" y="240" class="figure-text"><tspan> How many brown </tspan><tspan x="0" dy="1.5em"> things are there? </tspan></text><text x="170" y="240" class="figure-text"><tspan> How many yellow </tspan><tspan x="170" dy="1.5em"> things are there? </tspan></text></g></svg>
  </figure>
  <p>
    The network seems to be softly switching where in the image it is looking,
    based on the task description. It is quite interesting that these semantically
    meaningful interpolation behaviors emerge, as the network has not been
    trained to act this way.
  </p>
  <p>
    Despite these similarities across problem settings, we also observe
    qualitative differences in the way in which FiLM parameters cluster as a
    function of the task description. Unlike the style transfer model, the
    visual reasoning model sometimes exhibits several FiLM parameter
    sub-clusters for a given feature map.
  </p>
  <figure class="l-body" id="clevr-subcluster-diagram">
    <svg viewBox="0 0 704 410" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><text x="0" y="0" dy="1em" class="figure-text"> FiLM parameters of the <tspan style="font-weight: bold;">visual reasoning model</tspan> for 256 questions chosen randomly. </text><path d="M0,25l704,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="0" y="60" dy="1em" class="figure-text"><tspan style="font-weight: bold;">Feature map 26</tspan> of the first FiLM layer. </text><path d="M0,85l300,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="404" y="60" dy="1em" class="figure-text"><tspan style="font-weight: bold;">Feature map 76</tspan> of the first FiLM layer. </text><path d="M404,85l300,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><g id="first-plot"><rect x="10" y="110" width="300" height="300" style="fill: none;"></rect><path id="x-axis" d="M 0 0 L 0 0" class="figure-path"></path><text id="x-axis-label" x="0" y="0" dy="0.4em" style="font-family: serif;" class="figure-text"></text><path d="M 0 0 L 0 0" id="y-axis" class="figure-path"></path><text id="y-axis-label" x="0" y="0" dy="1em" style="font-family: serif;" class="figure-text"></text></g><g id="second-plot"><rect x="404" y="110" width="300" height="300" style="fill: none;"></rect><path id="x-axis" d="M 0 0 L 0 0" class="figure-path"></path><text id="x-axis-label" x="0" y="0" dy="0.4em" style="font-family: serif;" class="figure-text"></text><path d="M 0 0 L 0 0" id="y-axis" class="figure-path"></path><text id="y-axis-label" x="0" y="0" dy="1em" style="font-family: serif;" class="figure-text"></text></g></svg>
  </figure>
  <p>
    At the very least, this may indicate that FiLM learns to operate in ways
    that are problem-specific, and that we should not expect to find a unified
    and problem-independent explanation for FiLM's success in modulating FiLM-ed
    networks. Perhaps the compositional or discrete nature of visual reasoning
    requires the model to implement several well-defined modes of operation
    which are less necessary for style transfer.
  </p>
  <p>
    Focusing on individual feature maps which exhibit sub-clusters, we can try
    to infer how questions regroup by color-coding the scatter plots by question
    type.
  </p>
  <figure class="l-body" id="clevr-subcluster-color-diagram">
    <svg viewBox="0 0 704 370" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><text x="0" y="0" dy="1em" class="figure-text"> FiLM parameters of the <tspan style="font-weight: bold;">visual reasoning model</tspan> for 256 questions chosen randomly. </text><path d="M0,30l704,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="0" y="60" dy="1em" class="figure-text"><tspan style="font-weight: bold;">Feature map 26</tspan> of the first FiLM layer. </text><path d="M0,90l250,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="300" y="60" dy="1em" class="figure-text"><tspan style="font-weight: bold;">Feature map 76</tspan> of the first FiLM layer. </text><path d="M300,90l250,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="590" y="60" dy="1em" class="figure-text"> Question type </text><path d="M590,90l114,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><g id="first-plot"><rect x="0" y="110" width="250" height="250" style="fill: none;"></rect><path id="x-axis" d="M 0 0 L 0 0" class="figure-path"></path><text id="x-axis-label" x="0" y="0" dy="0.4em" style="font-family: serif;" class="figure-text"></text><path d="M 0 0 L 0 0" id="y-axis" class="figure-path"></path><text id="y-axis-label" x="0" y="0" dy="1em" style="font-family: serif;" class="figure-text"></text></g><g id="second-plot"><rect x="300" y="110" width="250" height="250" style="fill: none;"></rect><path id="x-axis" d="M 0 0 L 0 0" class="figure-path"></path><text id="x-axis-label" x="0" y="0" dy="0.4em" style="font-family: serif;" class="figure-text"></text><path d="M 0 0 L 0 0" id="y-axis" class="figure-path"></path><text id="y-axis-label" x="0" y="0" dy="1em" style="font-family: serif;" class="figure-text"></text></g><g transform="translate(596, 110)" id="legend"></g><image x="677" y="100" height="27" width="27" xlink:href="images/pointer.svg"></image></svg>
  </figure>
  <p>
    Sometimes a clear pattern emerges, as in the right plot, where color-related
    questions concentrate in the top-right cluster &mdash; we observe that
    questions either are of type <em>Query color</em> or <em>Equal color</em>,
    or contain concepts related to color. Sometimes it is harder to draw a
    conclusion, as in the left plot, where question types are scattered across
    the three clusters.
  </p>
  <p>
    In cases where question types alone cannot explain the clustering of the
    FiLM parameters, we can turn to the conditioning content itself to gain
    an understanding of the mechanism at play. Let's take a look at two more
    plots: one for feature map 26 as in the previous figure, and another
    for a different feature map, also exhibiting several subclusters. This time
    we regroup points by the words which appear in their associated question.
  </p>
  <figure class="l-body" id="clevr-subcluster-color-words-diagram">
    <svg viewBox="0 0 704 390" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><text x="0" y="0" dy="1em" class="figure-text"> FiLM parameters of the <tspan style="font-weight: bold;">visual reasoning model</tspan> for 256 questions chosen randomly. </text><path d="M0,30l704,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="0" y="60" dy="1em" class="figure-text"><tspan><tspan style="font-weight: bold;">Feature map 26</tspan> suggests an object position </tspan><tspan x="0" dy="1.5em"> separation mechanism. </tspan></text><path d="M0,110l250,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="300" y="60" dy="1em" class="figure-text"><tspan><tspan style="font-weight: bold;">Feature map 92</tspan> suggests an object material </tspan><tspan x="300" dy="1.5em"> separation mechanism. </tspan></text><path d="M300,110l250,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="590" y="60" dy="2.5em" class="figure-text"> Word in question </text><path d="M590,110l114,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><g id="first-plot"><rect x="0" y="130" width="250" height="250" style="fill: none;"></rect><path id="x-axis" d="M 0 0 L 0 0" class="figure-path"></path><text id="x-axis-label" x="0" y="0" dy="0.4em" style="font-family: serif;" class="figure-text"></text><path d="M 0 0 L 0 0" id="y-axis" class="figure-path"></path><text id="y-axis-label" x="0" y="0" dy="1em" style="font-family: serif;" class="figure-text"></text></g><g id="second-plot"><rect x="300" y="130" width="250" height="250" style="fill: none;"></rect><path id="x-axis" d="M 0 0 L 0 0" class="figure-path"></path><text id="x-axis-label" x="0" y="0" dy="0.4em" style="font-family: serif;" class="figure-text"></text><path d="M 0 0 L 0 0" id="y-axis" class="figure-path"></path><text id="y-axis-label" x="0" y="0" dy="1em" style="font-family: serif;" class="figure-text"></text></g><g transform="translate(596, 130)" id="legend"></g><image x="677" y="120" height="27" width="27" xlink:href="images/pointer.svg"></image></svg>
  </figure>
  <p>
    In the left plot, the left subcluster corresponds to questions involving
    objects positioned <em>in front</em> of other objects, while the right
    subcluster corresponds to questions involving objects positioned
    <em>behind</em> other objects. In the right plot we see some evidence of
    separation based on object material: the left subcluster corresponds to
    questions involving <em>matte</em> and <em>rubber</em> objects, while the
    right subcluster contains questions about <em>shiny</em> or
    <em>metallic</em> objects.
  </p>
  <p>
    The presence of sub-clusters in the visual reasoning model also suggests
    that question interpolations may not always work reliably, but these
    sub-clusters don't preclude one from performing arithmetic on the question
    representations, as Perez et al. <d-cite key="perez2018film"></d-cite>
    report.
  </p>
  <figure class="l-body">
    <svg viewBox="0 0 704 430" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M10,185l684,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><defs><path id="arrow-right" d="M 0 0 C -2.779 1 -5.376 2.445 -7.69 4.28 L -6.14 0 L -7.69 -4.28 C -5.376 -2.445 -2.779 -1 0 0 Z"></path></defs><text x="10" y="0" dy="1em" class="figure-text"><tspan> The model incorrectly answers a question </tspan><tspan x="10" dy="1.5em"> which involves an unseen combination </tspan><tspan x="10" dy="1.5em"> of concepts (in <tspan style="font-weight: bold">bold</tspan>). </tspan></text><text x="10" y="220" dy="1em" class="figure-text"><tspan> Rather than using the FiLM parameters </tspan><tspan x="10" dy="1.5em"> of the FiLM generator, we can use those </tspan><tspan x="10" dy="1.5em"> produced by combining questions with </tspan><tspan x="10" dy="1.5em"> familiar combinations of concepts (in </tspan><tspan x="10" dy="1.5em"><tspan style="font-weight: bold">bold</tspan>). This corrects the model&#x27;s answer. </tspan></text><g transform="translate(90, 0)"><image x="260" y="0" width="192" height="127.67" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/analogy_image.jpg"></image><text x="260" y="150" style="font-style: italic;" class="figure-text"> Q: What is the <tspan style="font-weight: bold">blue</tspan> big <tspan style="font-weight: bold">cylinder</tspan> made of? </text><text x="490" y="70" dy="-1em" style="font-style: italic;" class="figure-text"> Q ? </text><path d="M 457 70 L 535 70" class="figure-path"></path><use x="535" y="70" xlink:href="#arrow-right" class="figure-path"></use><text x="545" y="70" dy="0.4em" class="figure-text" style="fill: red">Rubber </text><image x="260" y="220" width="192" height="127.67" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/analogy_image.jpg"></image><text x="260" y="370" style="font-style: italic;" class="figure-text"><tspan> Q<tspan dy="4px" class="subscript">A</tspan></tspan><tspan dy="-4px"> : What is the <tspan style="font-weight: bold">blue</tspan> big <tspan style="font-weight: bold">sphere</tspan> made of? </tspan><tspan x="260" dy="2em"> Q<tspan dy="4px" class="subscript">B</tspan></tspan><tspan dy="-4px"> : What is the <tspan style="font-weight: bold">green</tspan> big <tspan style="font-weight: bold">cylinder</tspan> made of? </tspan><tspan x="260" dy="2em"> Q<tspan dy="4px" class="subscript">C</tspan></tspan><tspan dy="-4px"> : What is the <tspan style="font-weight: bold">green</tspan> big <tspan style="font-weight: bold">sphere</tspan> made of? </tspan></text><text x="460" y="290" dy="-1em" style="font-style: italic;" class="figure-text"><tspan>Q</tspan><tspan dy="4px" class="subscript">A</tspan><tspan dy="-4px">+ Q</tspan><tspan dy="4px" class="subscript">B</tspan><tspan dy="-4px">- Q</tspan><tspan dy="4px" class="subscript">C</tspan><tspan dy="-4px"> ?</tspan></text><path d="M 457 290 L 535 290" class="figure-path"></path><use x="535" y="290" xlink:href="#arrow-right" class="figure-path"></use><text x="545" y="290" dy="0.4em" class="figure-text" style="fill: green">Metal </text></g></svg>
  </figure>
  <p>
    Perez et al. <d-cite key="perez2018film"></d-cite> report that this sort of
    task analogy is not always successful in correcting the model's answer, but
    it does point to an interesting fact about FiLM-ed networks: sometimes the
    model makes a mistake not because it is incapable of computing the correct
    output, but because it fails to produce the correct FiLM parameters for a
    given task description. The reverse can also be true: if the set of tasks
    the model was trained on is insufficiently rich, the computational
    primitives learned by the FiLM-ed network may be insufficient to ensure good
    generalization. For instance, a style transfer model may lack the ability to
    produce zebra-like patterns if there are no stripes in the styles it was
    trained on. This could explain why Ghiasi et al.
    <d-cite key="ghiasi2017exploring"></d-cite> report that their style transfer
    model's ability to produce pastiches for new styles degrades if it has been
    trained on an insufficiently large number of styles. Note however that in
    that case the FiLM generator's failure to generalize could also play a role,
    and further analysis would be needed to draw a definitive conclusion.
  </p>
  <p>
    This points to a separation between the various computational
    primitives learned by the FiLM-ed network and the "numerical recipes"
    learned by the FiLM generator: the model's ability to generalize depends
    both on its ability to parse new forms of task descriptions and on it having
    learned the required computational primitives to solve those tasks. We note
    that this multi-faceted notion of generalization is inherited directly from
    the multi-task point of view adopted by the FiLM framework.
  </p>
  <p>
    Let's now turn our attention back to the overal structural properties of FiLM
    parameters observed thus far. The existence of this structure has already
    been explored, albeit more indirectly, by Ghiasi et al.
    <d-cite key="ghiasi2017exploring"></d-cite> as well as Perez et al.
    <d-cite key="perez2018film"></d-cite>, who applied t-SNE
    <d-cite key="maaten2008visualizing"></d-cite> on the FiLM parameter values.
  </p>
  <div class="l-body-outset">
    <svg width="888" height="46" xmlns="http://www.w3.org/2000/svg">
      <text x="0" y="20" dy="1em" class="figure-text">
        t-SNE projection of FiLM parameters for many task descriptions.
      </text>
      <path d="M0,45l888,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"/>
    </svg>
  </div>
  <figure class="l-body-outset" id="tsne-diagram">
    <svg xmlns="http://www.w3.org/2000/svg" id="clevr-plot-svg"><g id="clevr-plot" style="z-index: -1;"><rect x="10" y="100" width="250" height="250" style="fill: none;"></rect></g><rect width="444" height="30" style="fill:white" transform="translate(0, 10)"></rect><rect width="150" height="360" style="fill:white" transform="translate(285, 10)"></rect><text x="0" y="10" dy="1em" class="figure-text"><tspan style="font-weight: bold;">Visual reasoning model</tspan></text><path d="M0,35l250,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="290" y="10" dy="1em" class="figure-text"> Question type </text><path d="M290,35l124,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><g transform="translate(300, 60)" id="clevr-legend"></g><image x="387" y="0" height="27" width="27" xlink:href="images/pointer.svg"></image><g transform="translate(294, 340)" style="cursor: pointer;" id="clevr-zoom"><rect width="120" height="20" class="figure-group figure-box"></rect><text x="60" y="10" dy="0.4em" style="text-anchor: middle;" class="figure-text">Reset pan / zoom</text></g></svg><svg xmlns="http://www.w3.org/2000/svg" id="style-transfer-plot-svg"><g id="style-transfer-plot" style="z-index: -1;"><rect x="0" y="100" width="250" height="250" style="fill: none;"></rect><circle cx="212" cy="218" r="15" style="stroke-width: 4px; fill: none;" class="figure-element"></circle></g><rect width="444" height="30" style="fill:white" transform="translate(0, 10)"></rect><rect width="150" height="270" style="fill:white" transform="translate(285, 10)"></rect><text x="0" y="10" dy="1em" class="figure-text"><tspan style="font-weight: bold;">Style transfer model</tspan></text><path d="M0,35l250,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><text x="290" y="10" dy="1em" class="figure-text"> Artist name </text><path d="M290,35l124,0" style="stroke-width: 1px; stroke: #666; opacity: 0.15;"></path><g transform="translate(300, 60)" id="style-transfer-legend"></g><image x="387" y="0" height="27" width="27" xlink:href="images/pointer.svg"></image><g transform="translate(294, 240)" style="cursor: pointer;" id="style-zoom"><rect width="120" height="20" class="figure-group figure-box"></rect><text x="60" y="10" dy="0.4em" style="text-anchor: middle;" class="figure-text">Reset pan / zoom</text></g></svg>
  </figure>
  <p>
    The projection on the left is inspired by a similar projection done by Perez
    et al. <d-cite key="perez2018film"></d-cite> for their visual reasoning
    model trained on CLEVR and shows how questions group by question type.
    The projection on the right is inspired by a similar projection done by
    Ghiasi et al. <d-cite key="ghiasi2017exploring"></d-cite> for their style
    transfer network. The projection does not cluster artists as neatly as the
    projection on the left, but this is to be expected, given that an artist's
    style may vary widely over time. However, we can still detect interesting
    patterns in the projection: note for instance the isolated cluster (circled
    in the figure) in which paintings by Ivan Shishkin and Rembrandt are
    aggregated. While these two painters exhibit fairly different styles, the
    cluster is a grouping of their sketches.
  </p>
  <figure class="l-body" id="style-explained-diagram">
    <svg viewBox="0 0 704 320" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><image x="0" y="0" width="173.91" height="250" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/woman-with-a-pink.jpg"></image><text x="0" y="260" dy="1em" class="figure-text"><tspan> Rembrandt&#x27;s <tspan style="font-style: italic;">Woman with a</tspan></tspan><tspan x="0" dy="1.5em"><tspan style="font-style: italic;">Pink</tspan>. </tspan></text><image x="260" y="0" width="177.78" height="250" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/a-woman-with-a-boy-in-the-forest.jpg"></image><text x="260" y="260" dy="1em" class="figure-text"><tspan> Shishkin&#x27;s <tspan style="font-style: italic;">Woman with a boy</tspan></tspan><tspan x="260" dy="1.5em"><tspan style="font-style: italic;">in the forest</tspan>. </tspan></text><image x="510" y="0" width="164.63" height="200" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/abraham-and-isaac.jpg"></image><image x="560" y="50" width="142.62" height="200" style="clip-path: inset(0 0 0 0 round 6px);" xlink:href="images/pines-on-the-beach.jpg"></image><text x="510" y="260" dy="1em" class="figure-text"><tspan> Sketches by Rembrandt and </tspan><tspan x="510" dy="1.5em"> Shishkin found in the same t-SNE </tspan><tspan x="510" dy="1.5em"> cluster. </tspan></text></svg>
  </figure>
  <p>
    To summarize, the way neural networks learn to use FiLM layers seems to
    vary from problem to problem, input to input, and even from feature to
    feature; there does not seem to be a single mechanism by which the
    network uses FiLM to condition computation. This flexibility may
    explain why FiLM-related methods have been successful across such a
    wide variety of domains.
  </p>

  <hr/>

  <h2>Discussion</h2>
  <p>
    Looking forward, there are still many unanswered questions.
    Do these experimental observations on FiLM-based architectures generalize to
    other related conditioning mechanisms, such as conditional biasing, sigmoidal
    gating, HyperNetworks, and bilinear transformations? When do feature-wise
    transformations outperform methods with stronger inductive biases and vice
    versa? Recent work combines feature-wise transformations with stronger
    inductive bias methods
    <d-cite key="strub2018visual,bahdanau2018learning,yang2018dataset"></d-cite>,
    which could be an optimal middle ground. Also, to what extent are FiLM's
    task representation properties
    inherent to FiLM, and to what extent do they emerge from other features
    of neural networks (i.e. non-linearities, FiLM generator
    depth, etc.)? If you are interested in exploring these or other
    questions about FiLM, we recommend looking into the code bases for
    FiLM models for <a href="https://github.com/ethanjperez/film">visual reasoning</a>
    <d-cite key="perez2018film"></d-cite> and <a href="https://github.com/tensorflow/magenta/tree/master/magenta/models/arbitrary_image_stylization">style transfer</a>
    <d-cite key="ghiasi2017exploring"></d-cite> which we used as a
    starting point for our experiments here.
  </p>
  <p>
    Finally, the fact that changes on the feature level alone are able to
    compound into large and meaningful modulations of the FiLM-ed network is
    still very surprising to us, and hopefully future work will uncover deeper
    explanations. For now, though, it is a question that
    evokes the even grander mystery of how neural networks in general compound
    simple operations like matrix multiplications and element-wise
    non-linearities into semantically meaningful transformations.
  </p>
</d-article>

<d-appendix>
  <h3 id="bibliographic-notes">Bibliographic Notes</h3>
  <p>
      Multiplicative interactions have succeeded on various tasks, ever since
      they were introduced in vision as "mapping units" <d-cite key="hinton1981a"></d-cite>
      and "dynamic mappings" <d-cite key="vonderMalsburg1994the"></d-cite>
      around 40 years ago.  These tasks include Character-level Language
      Modeling<d-cite key="sutskever2011generating"></d-cite>,
      Image Denoising<d-cite key="tang2012boltzmann"></d-cite>,
      Pose Estimation<d-cite key="taylor2009factored"></d-cite>,
      Tracking<d-cite key="ross2006combining,denil2012learning"></d-cite>,
      Action Recognition<d-cite key="le2011learning,taylor2010convolutional"></d-cite>,
      and, more generally, tasks involving relating or matching inputs, such as
      from different modalities or points in time
      <d-cite key="memisevic2013learning"></d-cite>.
  </p>
  <p>
    Many models lie on the spectrum between FiLM and Hypernetworks:
  </p>
  <ul>
    <li>
      Adaptive CNN <d-cite key="kang2017incorporating"></d-cite> predicts the
      value of several of the model's convolution filters as a function of
      auxiliary inputs like camera perspective, level of noise, etc. The
      resulting convolution filters turn out to be very effective in difficult
      vision tasks such as crowd counting or image deblurring.
    </li>
    <li>
      Residual Adapters <d-cite key="rebuffi2017residualadapters"></d-cite> also
      propose to predict entire convolutional filters conditioned on the visual
      recognition domain they are operating in.
    </li>
    <li>
      In zero-shot/one-shot learning, Ba et al.
      <d-cite key="lei2015predicting"></d-cite> propose a model that predicts
      convolutional filters and classifiers weights based on textual
      descriptions of object classes.
    </li>
    <li>
      In reinforcement learning, Oh et al. <d-cite key="oh2017zero"></d-cite>
      propose a model that computes the parameters of a
      convolutional policy network conditioned on the task description.
    </li>
  </ul>
  <p>
    Tenenbaum and Freeman <d-cite key="tenenbaum1997separating"></d-cite> first
    introduced bilinear models in the vision community to better disentangle
    latent perceptual factors. The authors wanted to separate an image's style
    from its content, arguing that classic linear models were not rich enough to
    extract such complex interaction. They demonstrate the effectiveness of
    their approach by applying it to spoken vowel identification or zero-shot
    font classification. Notable applications include:
  </p>
  <ul>
    <li>
      Chuang et al. <d-cite key="chuang2002facial"></d-cite> perform facial
      animation using bilinear transformations by separating key facial features
      (the style) from visual emotions (the content). Their method can modify
      a speaking subject's expression in recorded sequence from happy to angry
      or neutral.
    </li>
    <li>
      Chu and Park <d-cite key="chu2009personalized"></d-cite> and Yang et al.
      <d-cite key="yang2011like"></d-cite> apply bilinear models to
      recommendation systems by extracting user and item information in various
      settings. More generally, recommendation systems rely heavily on matrix
      factorization methods <d-cite key="koren2009matrix"></d-cite>, which can
      be viewed as a bilinear model where one of the latent vectors is
      fixed<d-cite key="tenenbaum1997separating"></d-cite>.
    </li>
    <li>
      More recently, bilinear models have inspired new neural architectures in
      visual recognition <d-cite key="lin2015bilinear"></d-cite>, video action
      recognition <d-cite key="feichtenhofer2016convolutional"></d-cite>, and
      visual question-answering<d-cite key="fukui2016multimodal"></d-cite>.
    </li>
  </ul>
  <h3>Acknowledgements</h3>
  <p>
    This article would be nowhere near where it is today without the honest and
    constructive feedback we received from various people across several
    organizations. We would like to thank Chris Olah and Shan Carter from the
    Distill editorial team as well as Ludwig Schubert from the Google Brain team for being
    so generous with their time and advice. We would also like to thank Archy de
    Berker, Xavier Snelgrove, Pedro Oliveira Pinheiro, Alexei Nordell-Markovits,
    Masha Krol, and Minh Dao from Element AI; Roland Memisevic from TwentyBN;
    Dzmitry Bahdanau from MILA; Ameesh Shah and Will Levine from Rice
    University; Dhanush Radhakrishnan from Roivant Sciences; Raymond Cano from
    Plaid; Eleni Triantafillou from Toronto University; Olivier Pietquin and
    Jon Shlens from Google Brain; and Jrmie Mary from Criteo.
  </p>

  <h3>Discussion and Review</h3>
  <p>
    <a href="https://github.com/distillpub/post--feature-wise-transformations/issues/156">Review 1 - Anonymous </a><br>
    <a href="https://github.com/distillpub/post--feature-wise-transformations/issues/158">Review 2 - Anonymous </a><br>
    <a href="https://github.com/distillpub/post--feature-wise-transformations/issues/159">Review 3 - Chris Olah</a><br>
  </p>

  <d-footnote-list></d-footnote-list>
  <d-citation-list></d-citation-list>
</d-appendix>

<!-- bibliography will be inlined during Distill pipeline's pre-rendering -->
<d-bibliography src="bibliography.bib"></d-bibliography>

<script type="text/javascript" src="index.bundle.js"></script></body>
